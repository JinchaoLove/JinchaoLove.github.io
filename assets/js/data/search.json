{
      
        "0": {
          "doc": "Archives",
          "title": "Archives",
          "content": "\n",
          "url": "/blog/archives/",
          
          "relUrl": "/blog/archives/"
        }
      ,
        "1": {
          "doc": "Categories",
          "title": "Categories",
          "content": "\n",
          "url": "/blog/categories/",
          
          "relUrl": "/blog/categories/"
        }
      ,
        "2": {
          "doc": "Tags",
          "title": "Tags",
          "content": "\n",
          "url": "/blog/tags/",
          
          "relUrl": "/blog/tags/"
        }
      ,
        "3": {
          "doc": "About",
          "title": "Jinchao Li",
          "content": "\n      Ph.D. Candidate <a href=\"/assets/papers/CV_jinchaoli.pdf\" target=\"_blank\">[Resume]</a><br />\n      <a href=\"https://cuhk.edu.hk\">The Chinese University of Hong Kong</a><br />\n      Hong Kong, China<br />\n      Email: jinchaolovefy [at] gmail.com<br />\n      <div class=\"social\">\n        \n  \n\n  \n    <a href=\"javascript:location.href = 'mailto:' + ['jinchaolovefy','gmail.com'].join('@')\" data-bs-toggle=\"tooltip\" data-bs-placement=\"top\" aria-label=\"email\" data-bs-original-title=\"email\" link-attr-ignore=\"\" style=\"color: #0072c5;\">\n      <i class=\"fas fa-envelope\"></i>\n    </a>\n  \n\n  \n\n  \n    <a href=\"https://scholar.google.com/citations?hl=en&amp;user=SB7xjMoAAAAJ\" data-bs-toggle=\"tooltip\" data-bs-placement=\"top\" aria-label=\"google-scholar\" data-bs-original-title=\"google-scholar\" link-attr-ignore=\"\" target=\"_blank\" rel=\"noopener noreferrer\" style=\"color: #5c92f6;\">\n      <i class=\"fa-brands fa-google-scholar\"></i>\n    </a>\n  \n\n  \n\n  \n    <a href=\"https://github.com/JinchaoLove\" data-bs-toggle=\"tooltip\" data-bs-placement=\"top\" aria-label=\"github\" data-bs-original-title=\"github\" link-attr-ignore=\"\" target=\"_blank\" rel=\"noopener noreferrer\">\n      <i class=\"fab fa-github\"></i>\n    </a>\n  \n\n  \n\n  \n    <a href=\"/feed.xml\" data-bs-toggle=\"tooltip\" data-bs-placement=\"top\" aria-label=\"rss\" data-bs-original-title=\"rss\" link-attr-ignore=\"\" style=\"color: #ee802f;\">\n      <i class=\"fas fa-rss\"></i>\n    </a>\n  \n\n\n      </div>\n    </p>\n  </div>\n</div>\n\n",
          "url": "/",
          
          "relUrl": "/"
        },
        "4": {
          "doc": "About",
          "title": "Short Bio",
          "content": "\n\n<p>I am a final-year Ph.D. student at the <a href=\"https://www.se.cuhk.edu.hk/laboratories/human-computer-communications-laboratory/\">Human-Computer Communications Laboratory</a> (HCCL) in <a href=\"https://cuhk.edu.hk\">The Chinese University of Hong Kong</a>, advised by Prof. <a href=\"https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/\">Helen Meng</a>.\nBefore that, I obtained my B.S. with honors from <a href=\"https://www.nju.edu.cn\">Nanjing University</a> in 2019.\nMy research interests encompass <strong>human-centred AI in speech, language and healthcare</strong>, such as:</p>\n\n<ul>\n  <li>Neurocognitive Disorder Recognition</li>\n  <li>Emotion Recognition</li>\n  <li>Multimodal Large Language Models</li>\n</ul>\n\n",
          "url": "/#short-bio",
          
          "relUrl": "/#short-bio"
        },
        "5": {
          "doc": "About",
          "title": "News",
          "content": "\n\n<ul>\n  <li>2023.01: Two papers (<a href=\"https://arxiv.org/pdf/2303.08019.pdf\">1</a>, <a href=\"https://arxiv.org/pdf/2303.08027.pdf\">2</a>) accepted by ICASSP 2023.</li>\n  <li>2022-2023, Fist Term: Co-teaching “Conversational AI systems” (ASR part) with Prof. Meng, Prof. Wu and other nice colleagues in HCCL, SEEM, CUHK.</li>\n  <li>2022.09: Winner of two tasks in the “<a href=\"https://www.competitions.hume.ai/avb2022\">ACII Affective Vocal Bursts (A-VB)</a>” competition organized by <a href=\"https://hume.ai\">Hume AI</a>.</li>\n</ul>\n\n",
          "url": "/#news",
          
          "relUrl": "/#news"
        },
        "6": {
          "doc": "About",
          "title": "Publications",
          "content": "\n\n<div class=\"publications\" style=\"font-size: 1.03rem;\">\n  <ol class=\"bibliography\"><li><!-- _layouts/bib.html -->\n<div class=\"row\"><div class=\"col-sm-2\">\n      <div class=\"preview d-flex align-items-center\">\n\n<figure>\n  <picture>\n    <!-- Auto scaling with imagemagick -->\n    \n      <source class=\"responsive-img-srcset\" srcset=\"\n          /assets/papers/23/emotion2vec-800.webp 800w,\n          /assets/papers/23/emotion2vec-1280.webp 1280w,\n          /assets/papers/23/emotion2vec-1920.webp 1920w,\n          \" sizes=\"200px\" type=\"image/webp\" loading=\"lazy\" data-proofer-ignore=\"\" />\n    \n\n    <!-- Fallback to the original file -->\n    <img src=\"/assets/papers/23/emotion2vec.png\" class=\"preview rounded\" width=\"100%\" height=\"auto\" alt=\"papers/23/emotion2vec.png\" data-zoomable=\"\" onerror=\"this.onerror=null; $('.responsive-img-srcset').remove();\" loading=\"lazy\" />\n  </picture>\n</figure>\n</div>\n    </div><!-- Entry bib key -->\n  <div id=\"ma2023emotion2vec\" class=\"col-sm-10\">\n    <!-- Title -->\n    <div class=\"title\">emotion2vec: Self-Supervised Pre-Training for Speech Emotion Representation</div>\n    <!-- Author -->\n    <div class=\"author\">\n      \n\n      Ziyang\n            Ma,&nbsp;Zhisheng\n            Zheng,&nbsp;Jiaxin\n            Ye,&nbsp;<strong><u>Jinchao\n            Li</u></strong>,&nbsp;Zhifu\n            Gao,&nbsp;Shiliang\n            Zhang,&nbsp;and&nbsp;Xie\n            Chen</div>\n\n    <!-- Journal/Book title and date -->\n    \n    \n    <div class=\"periodical\">\n      <em>arXiv:2312.15185</em>, 2023\n    </div>\n    <div class=\"periodical\">\n      \n    </div>\n\n    <!-- Links/Buttons -->\n    <div class=\"links\">\n        <button class=\"abstract btn btn-sm z-depth-0\" title=\"Click to show/hide abstract\">ABS</button>\n        <button class=\"bibtex btn btn-sm z-depth-0\" title=\"Click to show/hide bibtex\">BIB</button>\n        <a href=\"https://arxiv.org/pdf/2312.15185.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\">PDF</a>\n        <a href=\"https://github.com/ddlBoJack/emotion2vec\" class=\"btn btn-sm z-depth-0\" role=\"button\">CODE</a>\n    </div>\n    \n      \n      \n      \n\n    <!-- Hidden abstract block -->\n      <div class=\"abstract hidden\">\n        <p>We propose emotion2vec, a universal speech emotion representation model. \n  emotion2vec is pre-trained on open-source unlabeled emotion data through self-supervised online distillation, combining utterance-level loss and frame-level loss during pre-training. \n  emotion2vec outperforms state-of-the-art pre-trained universal models and emotion specialist models by only training linear layers for the speech emotion recognition task on the mainstream IEMOCAP dataset. \n  In addition, emotion2vec shows consistent improvements among 10 different languages of speech emotion recognition datasets. \n  emotion2vec also shows excellent results on other emotion tasks, such as song emotion recognition, emotion prediction in conversation, and sentiment analysis. \n  Comparison experiments, ablation experiments, and visualization comprehensively demonstrate the universal capability of the proposed emotion2vec. \n  To the best of our knowledge, emotion2vec is the first universal representation model in various emotion-related tasks, filling a gap in the field.</p>\n      </div><!-- Hidden bibtex block -->\n      <div class=\"bibtex hidden\"><figure class=\"highlight\"><pre><code class=\"language-bibtex\" data-lang=\"bibtex\"><span class=\"nc\">@article</span><span class=\"p\">{</span><span class=\"nl\">ma2023emotion2vec</span><span class=\"p\">,</span>\n  <span class=\"na\">url</span> <span class=\"p\">=</span> <span class=\"s\">{https://arxiv.org/abs/2312.15185}</span><span class=\"p\">,</span>\n  <span class=\"na\">title</span> <span class=\"p\">=</span> <span class=\"s\">{emotion2vec: Self-Supervised Pre-Training for Speech Emotion Representation}</span><span class=\"p\">,</span>\n  <span class=\"na\">author</span> <span class=\"p\">=</span> <span class=\"s\">{Ma, Ziyang and Zheng, Zhisheng and Ye, Jiaxin and Li, Jinchao and Gao, Zhifu and Zhang, Shiliang and Chen, Xie}</span><span class=\"p\">,</span>\n  <span class=\"na\">journal</span> <span class=\"p\">=</span> <span class=\"s\">{arXiv:2312.15185}</span><span class=\"p\">,</span>\n  <span class=\"na\">year</span> <span class=\"p\">=</span> <span class=\"s\">{2023}</span>\n<span class=\"p\">}</span></code></pre></figure></div>\n\n    </div>\n</div>\n</li>\n<li><!-- _layouts/bib.html -->\n<div class=\"row\"><div class=\"col-sm-2\">\n      <div class=\"preview d-flex align-items-center\">\n\n<figure>\n  <picture>\n    <!-- Auto scaling with imagemagick -->\n    \n      <source class=\"responsive-img-srcset\" srcset=\"\n          /assets/papers/23/MultiAD_ICASSP23-800.webp 800w,\n          /assets/papers/23/MultiAD_ICASSP23-1280.webp 1280w,\n          /assets/papers/23/MultiAD_ICASSP23-1920.webp 1920w,\n          \" sizes=\"200px\" type=\"image/webp\" loading=\"lazy\" data-proofer-ignore=\"\" />\n    \n\n    <!-- Fallback to the original file -->\n    <img src=\"/assets/papers/23/MultiAD_ICASSP23.png\" class=\"preview rounded\" width=\"100%\" height=\"auto\" alt=\"papers/23/MultiAD_ICASSP23.png\" data-zoomable=\"\" onerror=\"this.onerror=null; $('.responsive-img-srcset').remove();\" loading=\"lazy\" />\n  </picture>\n</figure>\n</div>\n    </div><!-- Entry bib key -->\n  <div id=\"li2023leveraging\" class=\"col-sm-10\">\n    <!-- Title -->\n    <div class=\"title\">Leveraging Pretrained Representations With Task-Related Keywords for Alzheimer’s Disease Detection</div>\n    <!-- Author -->\n    <div class=\"author\">\n      \n\n      <strong><u>Jinchao\n            Li</u></strong>,&nbsp;Kaitao\n            Song,&nbsp;Junan\n            Li,&nbsp;Bo\n            Zheng,&nbsp;Dongsheng\n            Li,&nbsp;Xixin\n            Wu,&nbsp;Xunying\n            Liu, and Helen\n          Meng</div>\n\n    <!-- Journal/Book title and date -->\n    \n    \n    <div class=\"periodical\">\n      <em>In ICASSP</em>, 2023\n    </div>\n    <div class=\"periodical\">\n      \n    </div>\n\n    <!-- Links/Buttons -->\n    <div class=\"links\">\n        <button class=\"abstract btn btn-sm z-depth-0\" title=\"Click to show/hide abstract\">ABS</button>\n        <button class=\"bibtex btn btn-sm z-depth-0\" title=\"Click to show/hide bibtex\">BIB</button>\n        <a href=\"https://arxiv.org/pdf/2303.08019.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\">PDF</a>\n        <a href=\"/assets/papers/23/AD_poster.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\" target=\"_blank\" rel=\"noopener noreferrer\">POSTER</a>\n    </div>\n    \n      \n      \n      \n\n    <!-- Hidden abstract block -->\n      <div class=\"abstract hidden\">\n        <p>With the global population aging rapidly, Alzheimer’s disease (AD) is particularly prominent in older adults, which has an insidious onset and leads to a gradual, irreversible deterioration in cognitive domains (memory, communication, etc.). Speech-based AD detection opens up the possibility of widespread screening and timely disease intervention. Recent advances in pre-trained models motivate AD detection modeling to shift from low-level features to high-level representations. This paper presents several efficient methods to extract better AD-related cues from high-level acoustic and linguistic features. Based on these features, the paper also proposes a novel task-oriented approach by modeling the relationship between the participants’ description and the cognitive task. Experiments are carried out on the ADReSS dataset in a binary classification setup, and models are evaluated on the unseen test set. Results and comparison with recent literature demonstrate the efficiency and superior performance of proposed acoustic, linguistic and task-oriented methods. The findings also show the importance of semantic and syntactic information, and feasibility of automation and generalization with the promising audio-only and task-oriented methods for the AD detection task.</p>\n      </div><!-- Hidden bibtex block -->\n      <div class=\"bibtex hidden\"><figure class=\"highlight\"><pre><code class=\"language-bibtex\" data-lang=\"bibtex\"><span class=\"nc\">@inproceedings</span><span class=\"p\">{</span><span class=\"nl\">li2023leveraging</span><span class=\"p\">,</span>\n  <span class=\"na\">url</span> <span class=\"p\">=</span> <span class=\"s\">{https://ieeexplore.ieee.org/document/10096205}</span><span class=\"p\">,</span>\n  <span class=\"na\">title</span> <span class=\"p\">=</span> <span class=\"s\">{Leveraging Pretrained Representations With Task-Related Keywords for Alzheimer’s Disease Detection}</span><span class=\"p\">,</span>\n  <span class=\"na\">author</span> <span class=\"p\">=</span> <span class=\"s\">{Li, Jinchao and Song, Kaitao and Li, Junan and Zheng, Bo and Li, Dongsheng and Wu, Xixin and Liu, Xunying and Meng, Helen}</span><span class=\"p\">,</span>\n  <span class=\"na\">booktitle</span> <span class=\"p\">=</span> <span class=\"s\">{ICASSP}</span><span class=\"p\">,</span>\n  <span class=\"na\">year</span> <span class=\"p\">=</span> <span class=\"s\">{2023}</span><span class=\"p\">,</span>\n  <span class=\"na\">organization</span> <span class=\"p\">=</span> <span class=\"s\">{IEEE}</span>\n<span class=\"p\">}</span></code></pre></figure></div>\n\n    </div>\n</div>\n</li>\n<li><!-- _layouts/bib.html -->\n<div class=\"row\"><div class=\"col-sm-2\">\n      <div class=\"preview d-flex align-items-center\">\n\n<figure>\n  <picture>\n    <!-- Auto scaling with imagemagick -->\n    \n      <source class=\"responsive-img-srcset\" srcset=\"\n          /assets/papers/23/AVB_ICASSP23-800.webp 800w,\n          /assets/papers/23/AVB_ICASSP23-1280.webp 1280w,\n          /assets/papers/23/AVB_ICASSP23-1920.webp 1920w,\n          \" sizes=\"200px\" type=\"image/webp\" loading=\"lazy\" data-proofer-ignore=\"\" />\n    \n\n    <!-- Fallback to the original file -->\n    <img src=\"/assets/papers/23/AVB_ICASSP23.png\" class=\"preview rounded\" width=\"100%\" height=\"auto\" alt=\"papers/23/AVB_ICASSP23.png\" data-zoomable=\"\" onerror=\"this.onerror=null; $('.responsive-img-srcset').remove();\" loading=\"lazy\" />\n  </picture>\n</figure>\n</div>\n    </div><!-- Entry bib key -->\n  <div id=\"li2023hierarchical\" class=\"col-sm-10\">\n    <!-- Title -->\n    <div class=\"title\">A Hierarchical Regression Chain Framework for Affective Vocal Burst Recognition</div>\n    <!-- Author -->\n    <div class=\"author\">\n      \n\n      <strong><u>Jinchao\n            Li</u></strong>,&nbsp;Xixin\n            Wu,&nbsp;Kaitao\n            Song,&nbsp;Dongsheng\n            Li,&nbsp;Xunying\n            Liu,&nbsp;and&nbsp;Helen\n            Meng</div>\n\n    <!-- Journal/Book title and date -->\n    \n    \n    <div class=\"periodical\">\n      <em>In ICASSP</em>, 2023\n    </div>\n    <div class=\"periodical\">\n      \n    </div>\n\n    <!-- Links/Buttons -->\n    <div class=\"links\">\n        <button class=\"abstract btn btn-sm z-depth-0\" title=\"Click to show/hide abstract\">ABS</button>\n        <button class=\"bibtex btn btn-sm z-depth-0\" title=\"Click to show/hide bibtex\">BIB</button>\n        <a href=\"https://arxiv.org/pdf/2303.08027.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\">PDF</a>\n        <a href=\"/assets/papers/23/AVB_poster.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\" target=\"_blank\" rel=\"noopener noreferrer\">POSTER</a>\n        <a href=\"https://github.com/JinchaoLove/AffectiveVocalBurstRecognition\" class=\"btn btn-sm z-depth-0\" role=\"button\">CODE</a>\n    </div>\n    \n      \n      \n      \n\n    <!-- Hidden abstract block -->\n      <div class=\"abstract hidden\">\n        <p>As a common way of emotion signaling via non-linguistic vocalizations, vocal burst (VB) plays an important role in daily social interaction. Understanding and modeling human vocal bursts are indispensable for developing robust and general artificial intelligence. Exploring computational approaches for understanding vocal bursts is attracting increasing research attention. In this work, we propose a hierarchical framework, based on chain regression models, for affective recognition from VBs, that explicitly considers multiple relationships: (i) between emotional states and diverse cultures; (ii) between low-dimensional (arousal &amp; valence) and high-dimensional (10 emotion classes) emotion spaces; and (iii) between various emotion classes within the high-dimensional space. To address the challenge of data sparsity, we also use self-supervised learning (SSL) representations with layer-wise and temporal aggregation modules. The proposed systems participated in the ACII Affective Vocal Burst (A-VB) Challenge 2022 and ranked first in the \"TWO” and \"CULTURE” tasks. Experimental results based on the ACII Challenge 2022 dataset demonstrate the superior performance of the proposed system and the effectiveness of considering multiple relationships using hierarchical regression chain models.</p>\n      </div><!-- Hidden bibtex block -->\n      <div class=\"bibtex hidden\"><figure class=\"highlight\"><pre><code class=\"language-bibtex\" data-lang=\"bibtex\"><span class=\"nc\">@inproceedings</span><span class=\"p\">{</span><span class=\"nl\">li2023hierarchical</span><span class=\"p\">,</span>\n  <span class=\"na\">url</span> <span class=\"p\">=</span> <span class=\"s\">{https://ieeexplore.ieee.org/document/10096395/}</span><span class=\"p\">,</span>\n  <span class=\"na\">title</span> <span class=\"p\">=</span> <span class=\"s\">{A Hierarchical Regression Chain Framework for Affective Vocal Burst Recognition}</span><span class=\"p\">,</span>\n  <span class=\"na\">author</span> <span class=\"p\">=</span> <span class=\"s\">{Li, Jinchao and Wu, Xixin and Song, Kaitao and Li, Dongsheng and Liu, Xunying and Meng, Helen}</span><span class=\"p\">,</span>\n  <span class=\"na\">booktitle</span> <span class=\"p\">=</span> <span class=\"s\">{ICASSP}</span><span class=\"p\">,</span>\n  <span class=\"na\">year</span> <span class=\"p\">=</span> <span class=\"s\">{2023}</span><span class=\"p\">,</span>\n  <span class=\"na\">organization</span> <span class=\"p\">=</span> <span class=\"s\">{IEEE}</span>\n<span class=\"p\">}</span></code></pre></figure></div>\n\n    </div>\n</div>\n</li>\n<li><!-- _layouts/bib.html -->\n<div class=\"row\"><div class=\"col-sm-2\">\n      <div class=\"preview d-flex align-items-center\">\n\n<figure>\n  <picture>\n    <!-- Auto scaling with imagemagick -->\n    \n      <source class=\"responsive-img-srcset\" srcset=\"\n          /assets/papers/22/MER-800.webp 800w,\n          /assets/papers/22/MER-1280.webp 1280w,\n          /assets/papers/22/MER-1920.webp 1920w,\n          \" sizes=\"200px\" type=\"image/webp\" loading=\"lazy\" data-proofer-ignore=\"\" />\n    \n\n    <!-- Fallback to the original file -->\n    <img src=\"/assets/papers/22/MER.png\" class=\"preview rounded\" width=\"100%\" height=\"auto\" alt=\"papers/22/MER.png\" data-zoomable=\"\" onerror=\"this.onerror=null; $('.responsive-img-srcset').remove();\" loading=\"lazy\" />\n  </picture>\n</figure>\n</div>\n    </div><!-- Entry bib key -->\n  <div id=\"li2022context\" class=\"col-sm-10\">\n    <!-- Title -->\n    <div class=\"title\">Context-Aware Multimodal Fusion for Emotion Recognition</div>\n    <!-- Author -->\n    <div class=\"author\">\n      \n\n      <strong><u>Jinchao\n            Li</u></strong>,&nbsp;Shuai\n            Wang,&nbsp;Yang\n            Chao,&nbsp;Xunying\n            Liu,&nbsp;and&nbsp;Helen\n            Meng</div>\n\n    <!-- Journal/Book title and date -->\n    \n    \n    <div class=\"periodical\">\n      <em>In INTERSPEECH</em>, 2022\n    </div>\n    <div class=\"periodical\">\n      \n    </div>\n\n    <!-- Links/Buttons -->\n    <div class=\"links\">\n        <button class=\"abstract btn btn-sm z-depth-0\" title=\"Click to show/hide abstract\">ABS</button>\n        <button class=\"bibtex btn btn-sm z-depth-0\" title=\"Click to show/hide bibtex\">BIB</button>\n        <a href=\"/assets/papers/22/MER_paper_IS22.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\" target=\"_blank\" rel=\"noopener noreferrer\">PDF</a>\n        <a href=\"/assets/papers/22/MER_poster_IS22.png\" class=\"btn btn-sm z-depth-0\" role=\"button\" target=\"_blank\" rel=\"noopener noreferrer\">POSTER</a>\n    </div>\n    \n      \n      \n      \n\n    <!-- Hidden abstract block -->\n      <div class=\"abstract hidden\">\n        <p>Automatic emotion recognition (AER) is an inherently complex multimodal task that aims to automatically determine the emotional state of a given expression. Recent works have witnessed the benefits of upstream pretrained models in both audio and textual modalities for the AER task. However, efforts are still needed to effectively integrate features across multiple modalities, devoting due considerations to granularity mismatch and asynchrony in time steps. In this work, we first validate the effectiveness of the upstream models in a unimodal setup and empirically find that partial fine-tuning of the pretrained model in the feature space can significantly boost performance. Moreover, we take the context of the current sentence to model a more accurate emotional state. Based on the unimodal setups, we further propose several multimodal fusion methods to combine high-level features from the audio and text modalities. Experiments are carried out on the IEMOCAP dataset in a 4-category classification problem and compared with state-of-the-art methods in recent literature. Results show that the proposed models gave a superior performance of up to 84.45% and 80.36% weighted accuracy scores respectively in Session 5 and 5-fold cross-validation settings.</p>\n      </div><!-- Hidden bibtex block -->\n      <div class=\"bibtex hidden\"><figure class=\"highlight\"><pre><code class=\"language-bibtex\" data-lang=\"bibtex\"><span class=\"nc\">@inproceedings</span><span class=\"p\">{</span><span class=\"nl\">li2022context</span><span class=\"p\">,</span>\n  <span class=\"na\">url</span> <span class=\"p\">=</span> <span class=\"s\">{https://www.isca-speech.org/archive/interspeech_2022/li22v_interspeech.html}</span><span class=\"p\">,</span>\n  <span class=\"na\">title</span> <span class=\"p\">=</span> <span class=\"s\">{Context-Aware Multimodal Fusion for Emotion Recognition}</span><span class=\"p\">,</span>\n  <span class=\"na\">author</span> <span class=\"p\">=</span> <span class=\"s\">{Li, Jinchao and Wang, Shuai and Chao, Yang and Liu, Xunying and Meng, Helen}</span><span class=\"p\">,</span>\n  <span class=\"na\">booktitle</span> <span class=\"p\">=</span> <span class=\"s\">{INTERSPEECH}</span><span class=\"p\">,</span>\n  <span class=\"na\">year</span> <span class=\"p\">=</span> <span class=\"s\">{2022}</span><span class=\"p\">,</span>\n  <span class=\"na\">organization</span> <span class=\"p\">=</span> <span class=\"s\">{IEEE}</span>\n<span class=\"p\">}</span></code></pre></figure></div>\n\n    </div>\n</div>\n</li>\n<li><!-- _layouts/bib.html -->\n<div class=\"row\"><div class=\"col-sm-2\">\n      <div class=\"preview d-flex align-items-center\">\n\n<figure>\n  <picture>\n    <!-- Auto scaling with imagemagick -->\n    \n      <source class=\"responsive-img-srcset\" srcset=\"\n          /assets/papers/21/Comp_AD-800.webp 800w,\n          /assets/papers/21/Comp_AD-1280.webp 1280w,\n          /assets/papers/21/Comp_AD-1920.webp 1920w,\n          \" sizes=\"200px\" type=\"image/webp\" loading=\"lazy\" data-proofer-ignore=\"\" />\n    \n\n    <!-- Fallback to the original file -->\n    <img src=\"/assets/papers/21/Comp_AD.png\" class=\"preview rounded\" width=\"100%\" height=\"auto\" alt=\"papers/21/Comp_AD.png\" data-zoomable=\"\" onerror=\"this.onerror=null; $('.responsive-img-srcset').remove();\" loading=\"lazy\" />\n  </picture>\n</figure>\n</div>\n    </div><!-- Entry bib key -->\n  <div id=\"li2021comparative\" class=\"col-sm-10\">\n    <!-- Title -->\n    <div class=\"title\">A Comparative Study of Acoustic and Linguistic Features Classification for Alzheimer’s Disease Detection</div>\n    <!-- Author -->\n    <div class=\"author\">\n      \n\n      <strong><u>Jinchao\n            Li</u></strong>,&nbsp;Jianwei\n            Yu,&nbsp;Zi\n            Ye,&nbsp;Simon\n            Wong,&nbsp;Manwai\n            Mak,&nbsp;Brian\n            Mak,&nbsp;Xunying\n            Liu, and Helen\n          Meng</div>\n\n    <!-- Journal/Book title and date -->\n    \n    \n    <div class=\"periodical\">\n      <em>In ICASSP</em>, 2021\n    </div>\n    <div class=\"periodical\">\n      \n    </div>\n\n    <!-- Links/Buttons -->\n    <div class=\"links\">\n        <button class=\"abstract btn btn-sm z-depth-0\" title=\"Click to show/hide abstract\">ABS</button>\n        <button class=\"bibtex btn btn-sm z-depth-0\" title=\"Click to show/hide bibtex\">BIB</button>\n        <a href=\"https://www1.se.cuhk.edu.hk/~hccl/publications/pub/ICASSP_jcli.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\">PDF</a>\n        <a href=\"/assets/papers/21/Comp_AD.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\" target=\"_blank\" rel=\"noopener noreferrer\">POSTER</a>\n        <a href=\"https://github.com/JinchaoLove/NCDdetection_ICASSP2021\" class=\"btn btn-sm z-depth-0\" role=\"button\">CODE</a>\n    </div>\n    \n      \n      \n      \n\n    <!-- Hidden abstract block -->\n      <div class=\"abstract hidden\">\n        <p>With the global population ageing rapidly, Alzheimer’s Disease (AD) is particularly prominent in older adults, which has an insidious onset followed by gradual, irreversible deterioration in cognitive domains (memory, communication, etc). Thus the detection of Alzheimer’s Disease is crucial for timely intervention to slow down disease progression. This paper presents a comparative study of different acoustic and linguistic features for the AD detection using various classifiers. Experimental results on ADReSS dataset reflect that the proposed models using ComParE, X-vector, Linguistics, TFIDF and BERT features are able to detect AD with high accuracy and sensitivity, and are comparable with the state-of-the-art results reported. While most previous work used manual transcripts, our results also indicate that similar or even better performance could be obtained using automatically recognized transcripts over manually collected ones. This work achieves accuracy scores at 0.67 for acoustic features and 0.88 for linguistic features on either manual or ASR transcripts on the ADReSS Challenge test set.</p>\n      </div><!-- Hidden bibtex block -->\n      <div class=\"bibtex hidden\"><figure class=\"highlight\"><pre><code class=\"language-bibtex\" data-lang=\"bibtex\"><span class=\"nc\">@inproceedings</span><span class=\"p\">{</span><span class=\"nl\">li2021comparative</span><span class=\"p\">,</span>\n  <span class=\"na\">url</span> <span class=\"p\">=</span> <span class=\"s\">{https://ieeexplore.ieee.org/document/9414147}</span><span class=\"p\">,</span>\n  <span class=\"na\">title</span> <span class=\"p\">=</span> <span class=\"s\">{A Comparative Study of Acoustic and Linguistic Features Classification for Alzheimer's Disease Detection}</span><span class=\"p\">,</span>\n  <span class=\"na\">author</span> <span class=\"p\">=</span> <span class=\"s\">{Li, Jinchao and Yu, Jianwei and Ye, Zi and Wong, Simon and Mak, Manwai and Mak, Brian and Liu, Xunying and Meng, Helen}</span><span class=\"p\">,</span>\n  <span class=\"na\">booktitle</span> <span class=\"p\">=</span> <span class=\"s\">{ICASSP}</span><span class=\"p\">,</span>\n  <span class=\"na\">year</span> <span class=\"p\">=</span> <span class=\"s\">{2021}</span><span class=\"p\">,</span>\n  <span class=\"na\">organization</span> <span class=\"p\">=</span> <span class=\"s\">{IEEE}</span>\n<span class=\"p\">}</span></code></pre></figure></div>\n\n    </div>\n</div>\n</li>\n<li><!-- _layouts/bib.html -->\n<div class=\"row\"><div class=\"col-sm-2\">\n      <div class=\"preview d-flex align-items-center\">\n\n<figure>\n  <picture>\n    <!-- Auto scaling with imagemagick -->\n    \n      <source class=\"responsive-img-srcset\" srcset=\"\n          /assets/papers/21/ASR_AD-800.webp 800w,\n          /assets/papers/21/ASR_AD-1280.webp 1280w,\n          /assets/papers/21/ASR_AD-1920.webp 1920w,\n          \" sizes=\"200px\" type=\"image/webp\" loading=\"lazy\" data-proofer-ignore=\"\" />\n    \n\n    <!-- Fallback to the original file -->\n    <img src=\"/assets/papers/21/ASR_AD.png\" class=\"preview rounded\" width=\"100%\" height=\"auto\" alt=\"papers/21/ASR_AD.png\" data-zoomable=\"\" onerror=\"this.onerror=null; $('.responsive-img-srcset').remove();\" loading=\"lazy\" />\n  </picture>\n</figure>\n</div>\n    </div><!-- Entry bib key -->\n  <div id=\"ye2021development\" class=\"col-sm-10\">\n    <!-- Title -->\n    <div class=\"title\">Development of the CUHK Elderly Speech Recognition System for Neurocognitive Disorder Detection Using the DementiaBank Corpus</div>\n    <!-- Author -->\n    <div class=\"author\">\n      \n\n      Zi\n            Ye,&nbsp;Shoukang\n            Hu,&nbsp;<strong><u>Jinchao\n            Li</u></strong>,&nbsp;Xurong\n            Xie,&nbsp;Mengzhe\n            Geng,&nbsp;Jianwei\n            Yu,&nbsp;Junhao\n            Xu, and\n          <span class=\"more-authors\" title=\"click to view 4 more authors\" onclick=\"\n                var element = $(this);\n                element.attr('title', '');\n                var more_authors_text = element.text() == '4 more authors' ? 'Boyang Xue, Shansong Liu, Xunying Liu, Helen Meng' : '4 more authors';\n                var cursorPosition = 0;\n                var textAdder = setInterval(function(){\n                  element.text(more_authors_text.substring(0, cursorPosition + 1));\n                  if (++cursorPosition == more_authors_text.length){\n                    clearInterval(textAdder);\n                  }\n              }, '10');\n            \">4 more authors</span></div>\n\n    <!-- Journal/Book title and date -->\n    \n    \n    <div class=\"periodical\">\n      <em>In ICASSP</em>, 2021\n    </div>\n    <div class=\"periodical\">\n      \n    </div>\n\n    <!-- Links/Buttons -->\n    <div class=\"links\">\n        <button class=\"abstract btn btn-sm z-depth-0\" title=\"Click to show/hide abstract\">ABS</button>\n        <button class=\"bibtex btn btn-sm z-depth-0\" title=\"Click to show/hide bibtex\">BIB</button>\n        <a href=\"https://www1.se.cuhk.edu.hk/~hccl/publications/pub/zye_revised_v4.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\">PDF</a>\n        <a href=\"/assets/papers/21/ASR_AD.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\" target=\"_blank\" rel=\"noopener noreferrer\">POSTER</a>\n    </div>\n    \n      \n      \n      \n\n    <!-- Hidden abstract block -->\n      <div class=\"abstract hidden\">\n        <p>Early diagnosis of Neurocognitive Disorder (NCD) is crucial in facilitating preventive care and timely treatment to delay further progression. This paper presents the development of a state-of-the-art automatic speech recognition (ASR) system built on the Dementia-Bank Pitt corpus for automatic NCD detection. Speed perturbation based audio data augmentation expanded the limited elderly speech data by four times. Large quantities of out-of-domain, non-aged adult speech were exploited by cross-domain adapting a 1000-hour LibriSpeech corpus trained LF-MMI factored TDNN system to DementiaBank. The variability among elderly speakers was modeled using i-Vector and learning hidden unit contributions (LHUC) based speaker adaptive training. Robust Bayesian estimation of TDNN systems and LHUC transforms were used in both cross-domain and speaker adaptation. A Transformer language model was also built to improve the final system performance. A word error rate (WER) reduction of 11.72% absolute (26.11% relative) was obtained over the baseline i-Vector adapted LF-MMI TDNN system on the evaluation data of 48 elderly speakers. The best NCD detection accuracy of 88%, comparable to that using the ground truth speech transcripts, was obtained using the textual features extracted from the final ASR system outputs.</p>\n      </div><!-- Hidden bibtex block -->\n      <div class=\"bibtex hidden\"><figure class=\"highlight\"><pre><code class=\"language-bibtex\" data-lang=\"bibtex\"><span class=\"nc\">@inproceedings</span><span class=\"p\">{</span><span class=\"nl\">ye2021development</span><span class=\"p\">,</span>\n  <span class=\"na\">url</span> <span class=\"p\">=</span> <span class=\"s\">{https://ieeexplore.ieee.org/document/9413634}</span><span class=\"p\">,</span>\n  <span class=\"na\">title</span> <span class=\"p\">=</span> <span class=\"s\">{Development of the CUHK Elderly Speech Recognition System for Neurocognitive Disorder Detection Using the DementiaBank Corpus}</span><span class=\"p\">,</span>\n  <span class=\"na\">author</span> <span class=\"p\">=</span> <span class=\"s\">{Ye, Zi and Hu, Shoukang and Li, Jinchao and Xie, Xurong and Geng, Mengzhe and Yu, Jianwei and Xu, Junhao and Xue, Boyang and Liu, Shansong and Liu, Xunying and Meng, Helen}</span><span class=\"p\">,</span>\n  <span class=\"na\">booktitle</span> <span class=\"p\">=</span> <span class=\"s\">{ICASSP}</span><span class=\"p\">,</span>\n  <span class=\"na\">year</span> <span class=\"p\">=</span> <span class=\"s\">{2021}</span><span class=\"p\">,</span>\n  <span class=\"na\">organization</span> <span class=\"p\">=</span> <span class=\"s\">{IEEE}</span>\n<span class=\"p\">}</span></code></pre></figure></div>\n\n    </div>\n</div>\n</li></ol>\n</div>\n\n",
          "url": "/#publications",
          
          "relUrl": "/#publications"
        },
        "7": {
          "doc": "About",
          "title": "Research Experience",
          "content": "\n\n<p><strong><em>Neurocognitive Disorder (NCD) Detection</em></strong></p>\n\n<p>  Advised by Prof. <a href=\"https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/\">Helen Meng</a> and Prof. <a href=\"https://www1.se.cuhk.edu.hk/~xyliu/\">Xunying Liu</a> @<a href=\"https://www.se.cuhk.edu.hk/laboratories/human-computer-communications-laboratory/\">HCCL</a>, <a href=\"https://cuhk.edu.hk\">CUHK</a>, Jul. 2020 - Now</p>\n\n<ul>\n  <li>Speech and language based NCD detection: feature engineering, multimodality, and adaptation.</li>\n  <li>Feature engineering: comparatively studied the NCD-related acoustic and linguistic features.</li>\n  <li>Multimodality: efficient fusion of acoustic, linguistic and demographic modalities.</li>\n</ul>\n\n<p><strong><em>Neurocognitive Disorder (NCD) Detection</em></strong></p>\n\n<p>  Advised by Dr. <a href=\"https://recmind.cn/\">Dongsheng Li</a> and <a href=\"https://www.microsoft.com/en-us/research/people/kaitaosong\">Kaitao Song</a> @<a href=\"https://www.msra.cn\">MSRA</a> Shanghai AI lab, Jun. 2022 - Oct. 2022</p>\n\n<ul>\n  <li>Multimodal and multilingual speech-based disease detection.</li>\n  <li>Machine learning interpretation.</li>\n</ul>\n\n<p><strong><em>Emotion Recognition (ER)</em></strong>, <strong><em>Speech Enhancement (SE)</em></strong></p>\n\n<p>  Advised by Dr. <a href=\"https://wsstriving.github.io\">Shuai Wang</a> @<a href=\"https://www.lightspeed-studios.com\">Tencent Lightspeed &amp; Quantum Studios</a>, Oct. 2021 - May 2022</p>\n\n<ul>\n  <li>Multimodal ER: context-aware multimodal fusion for the ER task.</li>\n  <li>Real-time monaural SE: FullSubNet-based denoiser for ASR with fbank information.</li>\n</ul>\n\n<p><strong><em>Source Counting (SC)</em></strong></p>\n\n<p>  Advised by Prof. <a href=\"https://acoustics.nju.edu.cn/rydw/szgk/js/lj/index.html\">Jing Lu</a> @<a href=\"https://www.nju.edu.cn\">NJU</a> and Mr. <a href=\"https://www.linkedin.com/in/长宝-朱-a9b778b6/\">Changbao Zhu</a> @<a href=\"https://en.horizon.cc\">Horizon Robotics</a>, Dec. 2018 - Apr. 2019</p>\n\n<ul>\n  <li>Binaural speech SC with similarity and correlation features in various acoustic scenarios.</li>\n  <li>Honored the “Excellent Undergraduate Thesis” in NJU, 2019. Published a patent in 2021.</li>\n</ul>\n\n",
          "url": "/#research-experience",
          
          "relUrl": "/#research-experience"
        },
        "8": {
          "doc": "About",
          "title": "Honors &amp; Awards",
          "content": "\n\n<ul>\n  <li>2022: Winner of two tasks in the <a href=\"https://www.competitions.hume.ai/avb2022\">ACII Affective Vocal Bursts (A-VB)</a> competition</li>\n  <li>2019: Excellent Undergraduate Thesis of Nanjing University</li>\n  <li>2018: Meritorious winner prize in <a href=\"https://www.comap.com/contests/mcm-icm\">American Mathematical Contest in Modeling</a></li>\n  <li>2017: Meritorious winner prize in <a href=\"https://en.mcm.edu.cn\">CUMCM</a>, ranked top 1.5% in China</li>\n  <li>2017: National Scholarship, awarded by the Ministry of Education in China</li>\n  <li>2016: First Prize, Elite Program Scholarship of Nanjing University</li>\n</ul>\n\n",
          "url": "/#honors--awards",
          
          "relUrl": "/#honors--awards"
        },
        "9": {
          "doc": "About",
          "title": "Miscellaneous",
          "content": "\n\n<p><strong><em>Academic Activities</em></strong></p>\n\n<ul>\n  <li>Co-teaching “Conversational AI systems” (ASR part) with Prof. Meng, Prof. Wu and other nice colleagues in HCCL, SEEM, CUHK.</li>\n  <li>Every term 2 during 2019-2023 in CUHK: teaching assistant in ENGG1120 (Linear Algebra for Engineers)</li>\n</ul>\n\n<p><strong><em>Volunteer and Leadership</em></strong></p>\n\n<ul>\n  <li>Associate organizing chair of <a href=\"https://phdforum.se.cuhk.edu.hk/2023/index.html\">2023 International Doctoral Forum</a>, 2023.</li>\n  <li>Worked as team leader in <a href=\"https://www.comap.com/contests/mcm-icm\">American Mathematical Contest in Modeling</a>, 2018.</li>\n  <li>Volunteered in psychological consulting with elderly people, folk-art teaching, etc.\n<!-- - Organized a rural education research in Jiangxi Province to investigate and call for more attention to rural children's growth and education. Honored the \"Top Ten Teams of Social Practice\" in NJU, 2016. --></li>\n</ul>\n\n<p><strong><em>Computer Competencies</em></strong></p>\n\n<ul>\n  <li>Python</li>\n  <li>MATLAB</li>\n</ul>\n\n",
          "url": "/#miscellaneous",
          
          "relUrl": "/#miscellaneous"
        },
        "10": {
          "doc": "About",
          "title": "About",
          "content": "<div class=\"row\">\n  <div class=\"col-sm-3\">\n    <div class=\"preview d-flex align-items-center\">\n      \n      \n\n<figure>\n  <picture>\n    <!-- Auto scaling with imagemagick -->\n    \n      <source class=\"responsive-img-srcset\" srcset=\"\n          /assets/img/avatar/Jinchao-800.webp 800w,\n          /assets/img/avatar/Jinchao-1280.webp 1280w,\n          /assets/img/avatar/Jinchao-1920.webp 1920w,\n          \" sizes=\"95vw\" type=\"image/webp\" loading=\"lazy\" data-proofer-ignore=\"\" />\n    \n\n    <!-- Fallback to the original file -->\n    <img src=\"/assets/img/avatar/Jinchao.png\" class=\"preview rounded\" width=\"200px\" height=\"auto\" alt=\"Jinchao Li\" data-zoomable=\"\" onerror=\"this.onerror=null; $('.responsive-img-srcset').remove();\" loading=\"lazy\" />\n  </picture>\n</figure>\n\n    </div>\n  </div>\n\n  <div class=\"col-sm-9\">\n    \n    <p>\n      ",
          "url": "/",
          
          "relUrl": "/"
        }
      ,
        "11": {
          "doc": "Publications",
          "title": "2023",
          "content": "\n<ol class=\"bibliography\"><li><!-- _layouts/bib.html -->\n<div class=\"row\"><div class=\"col-sm-2\">\n      <div class=\"preview d-flex align-items-center\">\n\n<figure>\n  <picture>\n    <!-- Auto scaling with imagemagick -->\n    \n      <source class=\"responsive-img-srcset\" srcset=\"\n          /assets/papers/23/emotion2vec-800.webp 800w,\n          /assets/papers/23/emotion2vec-1280.webp 1280w,\n          /assets/papers/23/emotion2vec-1920.webp 1920w,\n          \" sizes=\"200px\" type=\"image/webp\" loading=\"lazy\" data-proofer-ignore=\"\" />\n    \n\n    <!-- Fallback to the original file -->\n    <img src=\"/assets/papers/23/emotion2vec.png\" class=\"preview rounded\" width=\"100%\" height=\"auto\" alt=\"papers/23/emotion2vec.png\" data-zoomable=\"\" onerror=\"this.onerror=null; $('.responsive-img-srcset').remove();\" loading=\"lazy\" />\n  </picture>\n</figure>\n</div>\n    </div><!-- Entry bib key -->\n  <div id=\"ma2023emotion2vec\" class=\"col-sm-10\">\n    <!-- Title -->\n    <div class=\"title\">emotion2vec: Self-Supervised Pre-Training for Speech Emotion Representation</div>\n    <!-- Author -->\n    <div class=\"author\">\n      \n\n      Ziyang\n            Ma,&nbsp;Zhisheng\n            Zheng,&nbsp;Jiaxin\n            Ye,&nbsp;<strong><u>Jinchao\n            Li</u></strong>,&nbsp;Zhifu\n            Gao,&nbsp;Shiliang\n            Zhang,&nbsp;and&nbsp;Xie\n            Chen</div>\n\n    <!-- Journal/Book title and date -->\n    \n    \n    <div class=\"periodical\">\n      <em>arXiv:2312.15185</em>, 2023\n    </div>\n    <div class=\"periodical\">\n      \n    </div>\n\n    <!-- Links/Buttons -->\n    <div class=\"links\">\n        <button class=\"abstract btn btn-sm z-depth-0\" title=\"Click to show/hide abstract\">ABS</button>\n        <button class=\"bibtex btn btn-sm z-depth-0\" title=\"Click to show/hide bibtex\">BIB</button>\n        <a href=\"https://arxiv.org/pdf/2312.15185.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\">PDF</a>\n        <a href=\"https://github.com/ddlBoJack/emotion2vec\" class=\"btn btn-sm z-depth-0\" role=\"button\">CODE</a>\n    </div>\n    \n      \n      \n      \n\n    <!-- Hidden abstract block -->\n      <div class=\"abstract hidden\">\n        <p>We propose emotion2vec, a universal speech emotion representation model. \n  emotion2vec is pre-trained on open-source unlabeled emotion data through self-supervised online distillation, combining utterance-level loss and frame-level loss during pre-training. \n  emotion2vec outperforms state-of-the-art pre-trained universal models and emotion specialist models by only training linear layers for the speech emotion recognition task on the mainstream IEMOCAP dataset. \n  In addition, emotion2vec shows consistent improvements among 10 different languages of speech emotion recognition datasets. \n  emotion2vec also shows excellent results on other emotion tasks, such as song emotion recognition, emotion prediction in conversation, and sentiment analysis. \n  Comparison experiments, ablation experiments, and visualization comprehensively demonstrate the universal capability of the proposed emotion2vec. \n  To the best of our knowledge, emotion2vec is the first universal representation model in various emotion-related tasks, filling a gap in the field.</p>\n      </div><!-- Hidden bibtex block -->\n      <div class=\"bibtex hidden\"><figure class=\"highlight\"><pre><code class=\"language-bibtex\" data-lang=\"bibtex\"><span class=\"nc\">@article</span><span class=\"p\">{</span><span class=\"nl\">ma2023emotion2vec</span><span class=\"p\">,</span>\n  <span class=\"na\">url</span> <span class=\"p\">=</span> <span class=\"s\">{https://arxiv.org/abs/2312.15185}</span><span class=\"p\">,</span>\n  <span class=\"na\">title</span> <span class=\"p\">=</span> <span class=\"s\">{emotion2vec: Self-Supervised Pre-Training for Speech Emotion Representation}</span><span class=\"p\">,</span>\n  <span class=\"na\">author</span> <span class=\"p\">=</span> <span class=\"s\">{Ma, Ziyang and Zheng, Zhisheng and Ye, Jiaxin and Li, Jinchao and Gao, Zhifu and Zhang, Shiliang and Chen, Xie}</span><span class=\"p\">,</span>\n  <span class=\"na\">journal</span> <span class=\"p\">=</span> <span class=\"s\">{arXiv:2312.15185}</span><span class=\"p\">,</span>\n  <span class=\"na\">year</span> <span class=\"p\">=</span> <span class=\"s\">{2023}</span>\n<span class=\"p\">}</span></code></pre></figure></div>\n\n    </div>\n</div>\n</li>\n<li><!-- _layouts/bib.html -->\n<div class=\"row\"><div class=\"col-sm-2\">\n      <div class=\"preview d-flex align-items-center\">\n\n<figure>\n  <picture>\n    <!-- Auto scaling with imagemagick -->\n    \n      <source class=\"responsive-img-srcset\" srcset=\"\n          /assets/papers/23/MultiAD_ICASSP23-800.webp 800w,\n          /assets/papers/23/MultiAD_ICASSP23-1280.webp 1280w,\n          /assets/papers/23/MultiAD_ICASSP23-1920.webp 1920w,\n          \" sizes=\"200px\" type=\"image/webp\" loading=\"lazy\" data-proofer-ignore=\"\" />\n    \n\n    <!-- Fallback to the original file -->\n    <img src=\"/assets/papers/23/MultiAD_ICASSP23.png\" class=\"preview rounded\" width=\"100%\" height=\"auto\" alt=\"papers/23/MultiAD_ICASSP23.png\" data-zoomable=\"\" onerror=\"this.onerror=null; $('.responsive-img-srcset').remove();\" loading=\"lazy\" />\n  </picture>\n</figure>\n</div>\n    </div><!-- Entry bib key -->\n  <div id=\"li2023leveraging\" class=\"col-sm-10\">\n    <!-- Title -->\n    <div class=\"title\">Leveraging Pretrained Representations With Task-Related Keywords for Alzheimer’s Disease Detection</div>\n    <!-- Author -->\n    <div class=\"author\">\n      \n\n      <strong><u>Jinchao\n            Li</u></strong>,&nbsp;Kaitao\n            Song,&nbsp;Junan\n            Li,&nbsp;Bo\n            Zheng,&nbsp;Dongsheng\n            Li,&nbsp;Xixin\n            Wu,&nbsp;Xunying\n            Liu, and Helen\n          Meng</div>\n\n    <!-- Journal/Book title and date -->\n    \n    \n    <div class=\"periodical\">\n      <em>In ICASSP</em>, 2023\n    </div>\n    <div class=\"periodical\">\n      \n    </div>\n\n    <!-- Links/Buttons -->\n    <div class=\"links\">\n        <button class=\"abstract btn btn-sm z-depth-0\" title=\"Click to show/hide abstract\">ABS</button>\n        <button class=\"bibtex btn btn-sm z-depth-0\" title=\"Click to show/hide bibtex\">BIB</button>\n        <a href=\"https://arxiv.org/pdf/2303.08019.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\">PDF</a>\n        <a href=\"/assets/papers/23/AD_poster.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\" target=\"_blank\" rel=\"noopener noreferrer\">POSTER</a>\n    </div>\n    \n      \n      \n      \n\n    <!-- Hidden abstract block -->\n      <div class=\"abstract hidden\">\n        <p>With the global population aging rapidly, Alzheimer’s disease (AD) is particularly prominent in older adults, which has an insidious onset and leads to a gradual, irreversible deterioration in cognitive domains (memory, communication, etc.). Speech-based AD detection opens up the possibility of widespread screening and timely disease intervention. Recent advances in pre-trained models motivate AD detection modeling to shift from low-level features to high-level representations. This paper presents several efficient methods to extract better AD-related cues from high-level acoustic and linguistic features. Based on these features, the paper also proposes a novel task-oriented approach by modeling the relationship between the participants’ description and the cognitive task. Experiments are carried out on the ADReSS dataset in a binary classification setup, and models are evaluated on the unseen test set. Results and comparison with recent literature demonstrate the efficiency and superior performance of proposed acoustic, linguistic and task-oriented methods. The findings also show the importance of semantic and syntactic information, and feasibility of automation and generalization with the promising audio-only and task-oriented methods for the AD detection task.</p>\n      </div><!-- Hidden bibtex block -->\n      <div class=\"bibtex hidden\"><figure class=\"highlight\"><pre><code class=\"language-bibtex\" data-lang=\"bibtex\"><span class=\"nc\">@inproceedings</span><span class=\"p\">{</span><span class=\"nl\">li2023leveraging</span><span class=\"p\">,</span>\n  <span class=\"na\">url</span> <span class=\"p\">=</span> <span class=\"s\">{https://ieeexplore.ieee.org/document/10096205}</span><span class=\"p\">,</span>\n  <span class=\"na\">title</span> <span class=\"p\">=</span> <span class=\"s\">{Leveraging Pretrained Representations With Task-Related Keywords for Alzheimer’s Disease Detection}</span><span class=\"p\">,</span>\n  <span class=\"na\">author</span> <span class=\"p\">=</span> <span class=\"s\">{Li, Jinchao and Song, Kaitao and Li, Junan and Zheng, Bo and Li, Dongsheng and Wu, Xixin and Liu, Xunying and Meng, Helen}</span><span class=\"p\">,</span>\n  <span class=\"na\">booktitle</span> <span class=\"p\">=</span> <span class=\"s\">{ICASSP}</span><span class=\"p\">,</span>\n  <span class=\"na\">year</span> <span class=\"p\">=</span> <span class=\"s\">{2023}</span><span class=\"p\">,</span>\n  <span class=\"na\">organization</span> <span class=\"p\">=</span> <span class=\"s\">{IEEE}</span>\n<span class=\"p\">}</span></code></pre></figure></div>\n\n    </div>\n</div>\n</li>\n<li><!-- _layouts/bib.html -->\n<div class=\"row\"><div class=\"col-sm-2\">\n      <div class=\"preview d-flex align-items-center\">\n\n<figure>\n  <picture>\n    <!-- Auto scaling with imagemagick -->\n    \n      <source class=\"responsive-img-srcset\" srcset=\"\n          /assets/papers/23/AVB_ICASSP23-800.webp 800w,\n          /assets/papers/23/AVB_ICASSP23-1280.webp 1280w,\n          /assets/papers/23/AVB_ICASSP23-1920.webp 1920w,\n          \" sizes=\"200px\" type=\"image/webp\" loading=\"lazy\" data-proofer-ignore=\"\" />\n    \n\n    <!-- Fallback to the original file -->\n    <img src=\"/assets/papers/23/AVB_ICASSP23.png\" class=\"preview rounded\" width=\"100%\" height=\"auto\" alt=\"papers/23/AVB_ICASSP23.png\" data-zoomable=\"\" onerror=\"this.onerror=null; $('.responsive-img-srcset').remove();\" loading=\"lazy\" />\n  </picture>\n</figure>\n</div>\n    </div><!-- Entry bib key -->\n  <div id=\"li2023hierarchical\" class=\"col-sm-10\">\n    <!-- Title -->\n    <div class=\"title\">A Hierarchical Regression Chain Framework for Affective Vocal Burst Recognition</div>\n    <!-- Author -->\n    <div class=\"author\">\n      \n\n      <strong><u>Jinchao\n            Li</u></strong>,&nbsp;Xixin\n            Wu,&nbsp;Kaitao\n            Song,&nbsp;Dongsheng\n            Li,&nbsp;Xunying\n            Liu,&nbsp;and&nbsp;Helen\n            Meng</div>\n\n    <!-- Journal/Book title and date -->\n    \n    \n    <div class=\"periodical\">\n      <em>In ICASSP</em>, 2023\n    </div>\n    <div class=\"periodical\">\n      \n    </div>\n\n    <!-- Links/Buttons -->\n    <div class=\"links\">\n        <button class=\"abstract btn btn-sm z-depth-0\" title=\"Click to show/hide abstract\">ABS</button>\n        <button class=\"bibtex btn btn-sm z-depth-0\" title=\"Click to show/hide bibtex\">BIB</button>\n        <a href=\"https://arxiv.org/pdf/2303.08027.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\">PDF</a>\n        <a href=\"/assets/papers/23/AVB_poster.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\" target=\"_blank\" rel=\"noopener noreferrer\">POSTER</a>\n        <a href=\"https://github.com/JinchaoLove/AffectiveVocalBurstRecognition\" class=\"btn btn-sm z-depth-0\" role=\"button\">CODE</a>\n    </div>\n    \n      \n      \n      \n\n    <!-- Hidden abstract block -->\n      <div class=\"abstract hidden\">\n        <p>As a common way of emotion signaling via non-linguistic vocalizations, vocal burst (VB) plays an important role in daily social interaction. Understanding and modeling human vocal bursts are indispensable for developing robust and general artificial intelligence. Exploring computational approaches for understanding vocal bursts is attracting increasing research attention. In this work, we propose a hierarchical framework, based on chain regression models, for affective recognition from VBs, that explicitly considers multiple relationships: (i) between emotional states and diverse cultures; (ii) between low-dimensional (arousal &amp; valence) and high-dimensional (10 emotion classes) emotion spaces; and (iii) between various emotion classes within the high-dimensional space. To address the challenge of data sparsity, we also use self-supervised learning (SSL) representations with layer-wise and temporal aggregation modules. The proposed systems participated in the ACII Affective Vocal Burst (A-VB) Challenge 2022 and ranked first in the \"TWO” and \"CULTURE” tasks. Experimental results based on the ACII Challenge 2022 dataset demonstrate the superior performance of the proposed system and the effectiveness of considering multiple relationships using hierarchical regression chain models.</p>\n      </div><!-- Hidden bibtex block -->\n      <div class=\"bibtex hidden\"><figure class=\"highlight\"><pre><code class=\"language-bibtex\" data-lang=\"bibtex\"><span class=\"nc\">@inproceedings</span><span class=\"p\">{</span><span class=\"nl\">li2023hierarchical</span><span class=\"p\">,</span>\n  <span class=\"na\">url</span> <span class=\"p\">=</span> <span class=\"s\">{https://ieeexplore.ieee.org/document/10096395/}</span><span class=\"p\">,</span>\n  <span class=\"na\">title</span> <span class=\"p\">=</span> <span class=\"s\">{A Hierarchical Regression Chain Framework for Affective Vocal Burst Recognition}</span><span class=\"p\">,</span>\n  <span class=\"na\">author</span> <span class=\"p\">=</span> <span class=\"s\">{Li, Jinchao and Wu, Xixin and Song, Kaitao and Li, Dongsheng and Liu, Xunying and Meng, Helen}</span><span class=\"p\">,</span>\n  <span class=\"na\">booktitle</span> <span class=\"p\">=</span> <span class=\"s\">{ICASSP}</span><span class=\"p\">,</span>\n  <span class=\"na\">year</span> <span class=\"p\">=</span> <span class=\"s\">{2023}</span><span class=\"p\">,</span>\n  <span class=\"na\">organization</span> <span class=\"p\">=</span> <span class=\"s\">{IEEE}</span>\n<span class=\"p\">}</span></code></pre></figure></div>\n\n    </div>\n</div>\n</li></ol>\n",
          "url": "/publications/",
          
          "relUrl": "/publications/"
        },
        "12": {
          "doc": "Publications",
          "title": "2022",
          "content": "\n<ol class=\"bibliography\"><li><!-- _layouts/bib.html -->\n<div class=\"row\"><div class=\"col-sm-2\">\n      <div class=\"preview d-flex align-items-center\">\n\n<figure>\n  <picture>\n    <!-- Auto scaling with imagemagick -->\n    \n      <source class=\"responsive-img-srcset\" srcset=\"\n          /assets/papers/22/MER-800.webp 800w,\n          /assets/papers/22/MER-1280.webp 1280w,\n          /assets/papers/22/MER-1920.webp 1920w,\n          \" sizes=\"200px\" type=\"image/webp\" loading=\"lazy\" data-proofer-ignore=\"\" />\n    \n\n    <!-- Fallback to the original file -->\n    <img src=\"/assets/papers/22/MER.png\" class=\"preview rounded\" width=\"100%\" height=\"auto\" alt=\"papers/22/MER.png\" data-zoomable=\"\" onerror=\"this.onerror=null; $('.responsive-img-srcset').remove();\" loading=\"lazy\" />\n  </picture>\n</figure>\n</div>\n    </div><!-- Entry bib key -->\n  <div id=\"li2022context\" class=\"col-sm-10\">\n    <!-- Title -->\n    <div class=\"title\">Context-Aware Multimodal Fusion for Emotion Recognition</div>\n    <!-- Author -->\n    <div class=\"author\">\n      \n\n      <strong><u>Jinchao\n            Li</u></strong>,&nbsp;Shuai\n            Wang,&nbsp;Yang\n            Chao,&nbsp;Xunying\n            Liu,&nbsp;and&nbsp;Helen\n            Meng</div>\n\n    <!-- Journal/Book title and date -->\n    \n    \n    <div class=\"periodical\">\n      <em>In INTERSPEECH</em>, 2022\n    </div>\n    <div class=\"periodical\">\n      \n    </div>\n\n    <!-- Links/Buttons -->\n    <div class=\"links\">\n        <button class=\"abstract btn btn-sm z-depth-0\" title=\"Click to show/hide abstract\">ABS</button>\n        <button class=\"bibtex btn btn-sm z-depth-0\" title=\"Click to show/hide bibtex\">BIB</button>\n        <a href=\"/assets/papers/22/MER_paper_IS22.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\" target=\"_blank\" rel=\"noopener noreferrer\">PDF</a>\n        <a href=\"/assets/papers/22/MER_poster_IS22.png\" class=\"btn btn-sm z-depth-0\" role=\"button\" target=\"_blank\" rel=\"noopener noreferrer\">POSTER</a>\n    </div>\n    \n      \n      \n      \n\n    <!-- Hidden abstract block -->\n      <div class=\"abstract hidden\">\n        <p>Automatic emotion recognition (AER) is an inherently complex multimodal task that aims to automatically determine the emotional state of a given expression. Recent works have witnessed the benefits of upstream pretrained models in both audio and textual modalities for the AER task. However, efforts are still needed to effectively integrate features across multiple modalities, devoting due considerations to granularity mismatch and asynchrony in time steps. In this work, we first validate the effectiveness of the upstream models in a unimodal setup and empirically find that partial fine-tuning of the pretrained model in the feature space can significantly boost performance. Moreover, we take the context of the current sentence to model a more accurate emotional state. Based on the unimodal setups, we further propose several multimodal fusion methods to combine high-level features from the audio and text modalities. Experiments are carried out on the IEMOCAP dataset in a 4-category classification problem and compared with state-of-the-art methods in recent literature. Results show that the proposed models gave a superior performance of up to 84.45% and 80.36% weighted accuracy scores respectively in Session 5 and 5-fold cross-validation settings.</p>\n      </div><!-- Hidden bibtex block -->\n      <div class=\"bibtex hidden\"><figure class=\"highlight\"><pre><code class=\"language-bibtex\" data-lang=\"bibtex\"><span class=\"nc\">@inproceedings</span><span class=\"p\">{</span><span class=\"nl\">li2022context</span><span class=\"p\">,</span>\n  <span class=\"na\">url</span> <span class=\"p\">=</span> <span class=\"s\">{https://www.isca-speech.org/archive/interspeech_2022/li22v_interspeech.html}</span><span class=\"p\">,</span>\n  <span class=\"na\">title</span> <span class=\"p\">=</span> <span class=\"s\">{Context-Aware Multimodal Fusion for Emotion Recognition}</span><span class=\"p\">,</span>\n  <span class=\"na\">author</span> <span class=\"p\">=</span> <span class=\"s\">{Li, Jinchao and Wang, Shuai and Chao, Yang and Liu, Xunying and Meng, Helen}</span><span class=\"p\">,</span>\n  <span class=\"na\">booktitle</span> <span class=\"p\">=</span> <span class=\"s\">{INTERSPEECH}</span><span class=\"p\">,</span>\n  <span class=\"na\">year</span> <span class=\"p\">=</span> <span class=\"s\">{2022}</span><span class=\"p\">,</span>\n  <span class=\"na\">organization</span> <span class=\"p\">=</span> <span class=\"s\">{IEEE}</span>\n<span class=\"p\">}</span></code></pre></figure></div>\n\n    </div>\n</div>\n</li></ol>\n",
          "url": "/publications/",
          
          "relUrl": "/publications/"
        },
        "13": {
          "doc": "Publications",
          "title": "2021",
          "content": "\n<ol class=\"bibliography\"><li><!-- _layouts/bib.html -->\n<div class=\"row\"><div class=\"col-sm-2\">\n      <div class=\"preview d-flex align-items-center\">\n\n<figure>\n  <picture>\n    <!-- Auto scaling with imagemagick -->\n    \n      <source class=\"responsive-img-srcset\" srcset=\"\n          /assets/papers/21/Comp_AD-800.webp 800w,\n          /assets/papers/21/Comp_AD-1280.webp 1280w,\n          /assets/papers/21/Comp_AD-1920.webp 1920w,\n          \" sizes=\"200px\" type=\"image/webp\" loading=\"lazy\" data-proofer-ignore=\"\" />\n    \n\n    <!-- Fallback to the original file -->\n    <img src=\"/assets/papers/21/Comp_AD.png\" class=\"preview rounded\" width=\"100%\" height=\"auto\" alt=\"papers/21/Comp_AD.png\" data-zoomable=\"\" onerror=\"this.onerror=null; $('.responsive-img-srcset').remove();\" loading=\"lazy\" />\n  </picture>\n</figure>\n</div>\n    </div><!-- Entry bib key -->\n  <div id=\"li2021comparative\" class=\"col-sm-10\">\n    <!-- Title -->\n    <div class=\"title\">A Comparative Study of Acoustic and Linguistic Features Classification for Alzheimer’s Disease Detection</div>\n    <!-- Author -->\n    <div class=\"author\">\n      \n\n      <strong><u>Jinchao\n            Li</u></strong>,&nbsp;Jianwei\n            Yu,&nbsp;Zi\n            Ye,&nbsp;Simon\n            Wong,&nbsp;Manwai\n            Mak,&nbsp;Brian\n            Mak,&nbsp;Xunying\n            Liu, and Helen\n          Meng</div>\n\n    <!-- Journal/Book title and date -->\n    \n    \n    <div class=\"periodical\">\n      <em>In ICASSP</em>, 2021\n    </div>\n    <div class=\"periodical\">\n      \n    </div>\n\n    <!-- Links/Buttons -->\n    <div class=\"links\">\n        <button class=\"abstract btn btn-sm z-depth-0\" title=\"Click to show/hide abstract\">ABS</button>\n        <button class=\"bibtex btn btn-sm z-depth-0\" title=\"Click to show/hide bibtex\">BIB</button>\n        <a href=\"https://www1.se.cuhk.edu.hk/~hccl/publications/pub/ICASSP_jcli.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\">PDF</a>\n        <a href=\"/assets/papers/21/Comp_AD.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\" target=\"_blank\" rel=\"noopener noreferrer\">POSTER</a>\n        <a href=\"https://github.com/JinchaoLove/NCDdetection_ICASSP2021\" class=\"btn btn-sm z-depth-0\" role=\"button\">CODE</a>\n    </div>\n    \n      \n      \n      \n\n    <!-- Hidden abstract block -->\n      <div class=\"abstract hidden\">\n        <p>With the global population ageing rapidly, Alzheimer’s Disease (AD) is particularly prominent in older adults, which has an insidious onset followed by gradual, irreversible deterioration in cognitive domains (memory, communication, etc). Thus the detection of Alzheimer’s Disease is crucial for timely intervention to slow down disease progression. This paper presents a comparative study of different acoustic and linguistic features for the AD detection using various classifiers. Experimental results on ADReSS dataset reflect that the proposed models using ComParE, X-vector, Linguistics, TFIDF and BERT features are able to detect AD with high accuracy and sensitivity, and are comparable with the state-of-the-art results reported. While most previous work used manual transcripts, our results also indicate that similar or even better performance could be obtained using automatically recognized transcripts over manually collected ones. This work achieves accuracy scores at 0.67 for acoustic features and 0.88 for linguistic features on either manual or ASR transcripts on the ADReSS Challenge test set.</p>\n      </div><!-- Hidden bibtex block -->\n      <div class=\"bibtex hidden\"><figure class=\"highlight\"><pre><code class=\"language-bibtex\" data-lang=\"bibtex\"><span class=\"nc\">@inproceedings</span><span class=\"p\">{</span><span class=\"nl\">li2021comparative</span><span class=\"p\">,</span>\n  <span class=\"na\">url</span> <span class=\"p\">=</span> <span class=\"s\">{https://ieeexplore.ieee.org/document/9414147}</span><span class=\"p\">,</span>\n  <span class=\"na\">title</span> <span class=\"p\">=</span> <span class=\"s\">{A Comparative Study of Acoustic and Linguistic Features Classification for Alzheimer's Disease Detection}</span><span class=\"p\">,</span>\n  <span class=\"na\">author</span> <span class=\"p\">=</span> <span class=\"s\">{Li, Jinchao and Yu, Jianwei and Ye, Zi and Wong, Simon and Mak, Manwai and Mak, Brian and Liu, Xunying and Meng, Helen}</span><span class=\"p\">,</span>\n  <span class=\"na\">booktitle</span> <span class=\"p\">=</span> <span class=\"s\">{ICASSP}</span><span class=\"p\">,</span>\n  <span class=\"na\">year</span> <span class=\"p\">=</span> <span class=\"s\">{2021}</span><span class=\"p\">,</span>\n  <span class=\"na\">organization</span> <span class=\"p\">=</span> <span class=\"s\">{IEEE}</span>\n<span class=\"p\">}</span></code></pre></figure></div>\n\n    </div>\n</div>\n</li>\n<li><!-- _layouts/bib.html -->\n<div class=\"row\"><div class=\"col-sm-2\">\n      <div class=\"preview d-flex align-items-center\">\n\n<figure>\n  <picture>\n    <!-- Auto scaling with imagemagick -->\n    \n      <source class=\"responsive-img-srcset\" srcset=\"\n          /assets/papers/21/ASR_AD-800.webp 800w,\n          /assets/papers/21/ASR_AD-1280.webp 1280w,\n          /assets/papers/21/ASR_AD-1920.webp 1920w,\n          \" sizes=\"200px\" type=\"image/webp\" loading=\"lazy\" data-proofer-ignore=\"\" />\n    \n\n    <!-- Fallback to the original file -->\n    <img src=\"/assets/papers/21/ASR_AD.png\" class=\"preview rounded\" width=\"100%\" height=\"auto\" alt=\"papers/21/ASR_AD.png\" data-zoomable=\"\" onerror=\"this.onerror=null; $('.responsive-img-srcset').remove();\" loading=\"lazy\" />\n  </picture>\n</figure>\n</div>\n    </div><!-- Entry bib key -->\n  <div id=\"ye2021development\" class=\"col-sm-10\">\n    <!-- Title -->\n    <div class=\"title\">Development of the CUHK Elderly Speech Recognition System for Neurocognitive Disorder Detection Using the DementiaBank Corpus</div>\n    <!-- Author -->\n    <div class=\"author\">\n      \n\n      Zi\n            Ye,&nbsp;Shoukang\n            Hu,&nbsp;<strong><u>Jinchao\n            Li</u></strong>,&nbsp;Xurong\n            Xie,&nbsp;Mengzhe\n            Geng,&nbsp;Jianwei\n            Yu,&nbsp;Junhao\n            Xu, and\n          <span class=\"more-authors\" title=\"click to view 4 more authors\" onclick=\"\n                var element = $(this);\n                element.attr('title', '');\n                var more_authors_text = element.text() == '4 more authors' ? 'Boyang Xue, Shansong Liu, Xunying Liu, Helen Meng' : '4 more authors';\n                var cursorPosition = 0;\n                var textAdder = setInterval(function(){\n                  element.text(more_authors_text.substring(0, cursorPosition + 1));\n                  if (++cursorPosition == more_authors_text.length){\n                    clearInterval(textAdder);\n                  }\n              }, '10');\n            \">4 more authors</span></div>\n\n    <!-- Journal/Book title and date -->\n    \n    \n    <div class=\"periodical\">\n      <em>In ICASSP</em>, 2021\n    </div>\n    <div class=\"periodical\">\n      \n    </div>\n\n    <!-- Links/Buttons -->\n    <div class=\"links\">\n        <button class=\"abstract btn btn-sm z-depth-0\" title=\"Click to show/hide abstract\">ABS</button>\n        <button class=\"bibtex btn btn-sm z-depth-0\" title=\"Click to show/hide bibtex\">BIB</button>\n        <a href=\"https://www1.se.cuhk.edu.hk/~hccl/publications/pub/zye_revised_v4.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\">PDF</a>\n        <a href=\"/assets/papers/21/ASR_AD.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\" target=\"_blank\" rel=\"noopener noreferrer\">POSTER</a>\n    </div>\n    \n      \n      \n      \n\n    <!-- Hidden abstract block -->\n      <div class=\"abstract hidden\">\n        <p>Early diagnosis of Neurocognitive Disorder (NCD) is crucial in facilitating preventive care and timely treatment to delay further progression. This paper presents the development of a state-of-the-art automatic speech recognition (ASR) system built on the Dementia-Bank Pitt corpus for automatic NCD detection. Speed perturbation based audio data augmentation expanded the limited elderly speech data by four times. Large quantities of out-of-domain, non-aged adult speech were exploited by cross-domain adapting a 1000-hour LibriSpeech corpus trained LF-MMI factored TDNN system to DementiaBank. The variability among elderly speakers was modeled using i-Vector and learning hidden unit contributions (LHUC) based speaker adaptive training. Robust Bayesian estimation of TDNN systems and LHUC transforms were used in both cross-domain and speaker adaptation. A Transformer language model was also built to improve the final system performance. A word error rate (WER) reduction of 11.72% absolute (26.11% relative) was obtained over the baseline i-Vector adapted LF-MMI TDNN system on the evaluation data of 48 elderly speakers. The best NCD detection accuracy of 88%, comparable to that using the ground truth speech transcripts, was obtained using the textual features extracted from the final ASR system outputs.</p>\n      </div><!-- Hidden bibtex block -->\n      <div class=\"bibtex hidden\"><figure class=\"highlight\"><pre><code class=\"language-bibtex\" data-lang=\"bibtex\"><span class=\"nc\">@inproceedings</span><span class=\"p\">{</span><span class=\"nl\">ye2021development</span><span class=\"p\">,</span>\n  <span class=\"na\">url</span> <span class=\"p\">=</span> <span class=\"s\">{https://ieeexplore.ieee.org/document/9413634}</span><span class=\"p\">,</span>\n  <span class=\"na\">title</span> <span class=\"p\">=</span> <span class=\"s\">{Development of the CUHK Elderly Speech Recognition System for Neurocognitive Disorder Detection Using the DementiaBank Corpus}</span><span class=\"p\">,</span>\n  <span class=\"na\">author</span> <span class=\"p\">=</span> <span class=\"s\">{Ye, Zi and Hu, Shoukang and Li, Jinchao and Xie, Xurong and Geng, Mengzhe and Yu, Jianwei and Xu, Junhao and Xue, Boyang and Liu, Shansong and Liu, Xunying and Meng, Helen}</span><span class=\"p\">,</span>\n  <span class=\"na\">booktitle</span> <span class=\"p\">=</span> <span class=\"s\">{ICASSP}</span><span class=\"p\">,</span>\n  <span class=\"na\">year</span> <span class=\"p\">=</span> <span class=\"s\">{2021}</span><span class=\"p\">,</span>\n  <span class=\"na\">organization</span> <span class=\"p\">=</span> <span class=\"s\">{IEEE}</span>\n<span class=\"p\">}</span></code></pre></figure></div>\n\n    </div>\n</div>\n</li></ol>\n",
          "url": "/publications/",
          
          "relUrl": "/publications/"
        },
        "14": {
          "doc": "Publications",
          "title": "2019",
          "content": "\n<ol class=\"bibliography\"><li><!-- _layouts/bib.html -->\n<div class=\"row\"><div class=\"col-sm-2\">\n      <div class=\"preview d-flex align-items-center\">\n\n<figure>\n  <picture>\n    <!-- Auto scaling with imagemagick -->\n    \n      <source class=\"responsive-img-srcset\" srcset=\"\n          /assets/papers/19/SC-800.webp 800w,\n          /assets/papers/19/SC-1280.webp 1280w,\n          /assets/papers/19/SC-1920.webp 1920w,\n          \" sizes=\"200px\" type=\"image/webp\" loading=\"lazy\" data-proofer-ignore=\"\" />\n    \n\n    <!-- Fallback to the original file -->\n    <img src=\"/assets/papers/19/SC.png\" class=\"preview rounded\" width=\"100%\" height=\"auto\" alt=\"papers/19/SC.png\" data-zoomable=\"\" onerror=\"this.onerror=null; $('.responsive-img-srcset').remove();\" loading=\"lazy\" />\n  </picture>\n</figure>\n</div>\n    </div><!-- Entry bib key -->\n  <div id=\"changbao2019method\" class=\"col-sm-10\">\n    <!-- Title -->\n    <div class=\"title\">Method, Device and Electronic Equipment for Determining Sound Source Information based on Microphone Array</div>\n    <!-- Author -->\n    <div class=\"author\">\n      \n\n      Changbao\n            Zhu,&nbsp;and&nbsp;<strong><u>Jinchao\n            Li</u></strong></div>\n\n    <!-- Journal/Book title and date -->\n    \n    \n    <div class=\"periodical\">\n      <em>In Patent: CN110148422B</em>, 2019\n    </div>\n    <div class=\"periodical\">\n      \n    </div>\n\n    <!-- Links/Buttons -->\n    <div class=\"links\">\n        <button class=\"abstract btn btn-sm z-depth-0\" title=\"Click to show/hide abstract\">ABS</button>\n        <a href=\"https://patent-image.qichacha.com/pdf/81a740a39373966f3730316bd32e08d5.pdf\" class=\"btn btn-sm z-depth-0\" role=\"button\">PDF</a>\n    </div>\n    \n      \n      \n      \n\n    <!-- Hidden abstract block -->\n      <div class=\"abstract hidden\">\n        <p>本公开实施例公开了一种基于传声器阵列确定声源信息的方法,其中,方法包括:确定传声器阵列采集的多路音频信号;确定所述多路音频信号的相似性度量信息;确定所述多路音频信号的相关性度量信息;基于所述相似性度量信息和所述相关性度量信息,确定声源信息.还公开了一种基于传声器阵列确定声源信息的装置,其中,装置包括:音频信号确定模块,相似性度量信息确定模块,相关性度量信息确定模块和声源信息确定模块.本公开实施例可以通过确定并基于传声器阵列采集的多路音频信号的相似性度量信息和相关性度量信息,确定声源信息,可以通过传声器阵列得到声源信息,方便后续进行行声源数量估计,可以保证声源数量估计的准确性.</p>\n      </div>\n\n    </div>\n</div>\n</li></ol>\n</div>\n",
          "url": "/publications/",
          
          "relUrl": "/publications/"
        },
        "15": {
          "doc": "Publications",
          "title": "Publications",
          "content": "<div class=\"publications\">\n  ",
          "url": "/publications/",
          
          "relUrl": "/publications/"
        }
      ,
        "16": {
          "doc": "Exchange Homepage and About",
          "title": "Exchange Homepage and About",
          "content": "<p>To change the default site homepage as <code class=\"language-plaintext highlighter-rouge\">About</code>, and the original paginator homepage as <code class=\"language-plaintext highlighter-rouge\">Blog</code>. It may be difficult since <a href=\"https://jekyllrb.com/docs/pagination/\">pagination</a> only works within <code class=\"language-plaintext highlighter-rouge\">index.html</code>, see similar <a href=\"https://github.com/cotes2020/jekyll-theme-chirpy/issues/711\">issue</a>.</p>\n\n<ol>\n  <li>\n    <p>Modify the front matters with permalink:</p>\n\n    <ul>\n      <li>Create a new folder, e.g. <code class=\"language-plaintext highlighter-rouge\">/blog/</code>, and move <code class=\"language-plaintext highlighter-rouge\">index.html</code> inside it.</li>\n      <li>Add <code class=\"language-plaintext highlighter-rouge\">permalink: /</code> in the front matter of <code class=\"language-plaintext highlighter-rouge\">/_tabs/about.md</code>.</li>\n    </ul>\n  </li>\n  <li>\n    <p>Add <code class=\"language-plaintext highlighter-rouge\">paginate_path</code> in <code class=\"language-plaintext highlighter-rouge\">/_config.yml</code> to point to the folder <code class=\"language-plaintext highlighter-rouge\">/blog/</code></p>\n\n    <div class=\"language-diff highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n</pre></td> --><td class=\"rouge-code\"><pre> + paginate_path: \"/blog/page:num/\"\n ...\n - permalink: /posts/:title/\n + permalink: /blog/:title/\n</pre></td></tr></tbody></table></code></pre></div>    </div>\n  </li>\n  <li>\n    <p>Add <code class=\"language-plaintext highlighter-rouge\">BLOG</code> as a new tab or navigation item, refer to this <a href=\"https://github.com/cotes2020/jekyll-theme-chirpy/issues/855\">issue</a>.</p>\n\n    <ul>\n      <li>\n        <p>Modify <code class=\"language-plaintext highlighter-rouge\">/_includes/sidebar.html</code></p>\n\n        <div class=\"language-html highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n</pre></td> --><td class=\"rouge-code\"><pre>  <span class=\"c\">&lt;!-- home --&gt;</span>\n  - <span class=\"nt\">&lt;li</span> <span class=\"na\">class=</span><span class=\"s\">\"nav-item{% if page.layout == 'home' %}{{ \"</span> <span class=\"na\">active</span> <span class=\"err\">\"</span> <span class=\"err\">}}{%</span> <span class=\"na\">endif</span> <span class=\"err\">%}\"</span><span class=\"nt\">&gt;</span>\n  + <span class=\"nt\">&lt;li</span> <span class=\"na\">class=</span><span class=\"s\">\"nav-item{% if page.url == '/' | relative_url %}{{ \"</span> <span class=\"na\">active</span> <span class=\"err\">\"</span> <span class=\"err\">}}{%</span> <span class=\"na\">endif</span> <span class=\"err\">%}\"</span><span class=\"nt\">&gt;</span>\n  <span class=\"nt\">&lt;a</span> <span class=\"na\">href=</span><span class=\"s\">\"{{ '/' | relative_url }}\"</span> <span class=\"na\">class=</span><span class=\"s\">\"nav-link\"</span><span class=\"nt\">&gt;</span>\n      <span class=\"nt\">&lt;i</span> <span class=\"na\">class=</span><span class=\"s\">\"fa-fw fas fa-home\"</span><span class=\"nt\">&gt;&lt;/i&gt;</span>\n      <span class=\"nt\">&lt;span&gt;</span>{{ site.data.locales[include.lang].tabs.home | upcase }}<span class=\"nt\">&lt;/span&gt;</span>\n  <span class=\"nt\">&lt;/a&gt;</span>\n  <span class=\"nt\">&lt;/li&gt;</span>\n  + <span class=\"c\">&lt;!-- blog --&gt;</span>\n  + <span class=\"nt\">&lt;li</span> <span class=\"na\">class=</span><span class=\"s\">\"nav-item{% if page.url == '/blog/' | relative_url %}{{ \"</span> <span class=\"na\">active</span> <span class=\"err\">\"</span> <span class=\"err\">}}{%</span> <span class=\"na\">endif</span> <span class=\"err\">%}\"</span><span class=\"nt\">&gt;</span>\n  +   <span class=\"nt\">&lt;a</span> <span class=\"na\">href=</span><span class=\"s\">\"{{ '/blog/' | relative_url }}\"</span> <span class=\"na\">class=</span><span class=\"s\">\"nav-link\"</span><span class=\"nt\">&gt;</span>\n  +     <span class=\"nt\">&lt;i</span> <span class=\"na\">class=</span><span class=\"s\">\"fa-fw fas fa-pen\"</span><span class=\"nt\">&gt;&lt;/i&gt;</span> \n  +     <span class=\"nt\">&lt;span&gt;</span>BLOG<span class=\"nt\">&lt;/span&gt;</span>\n  +   <span class=\"nt\">&lt;/a&gt;</span>\n  + <span class=\"nt\">&lt;/li&gt;</span>\n  <span class=\"c\">&lt;!-- the real tabs --&gt;</span>\n  {% for tab in site.tabs %}\n  +     {% if tab.url == '/' | relative_url %}{% continue %}{% endif %}\n</pre></td></tr></tbody></table></code></pre></div>        </div>\n      </li>\n      <li>\n        <p>Modify <code class=\"language-plaintext highlighter-rouge\">/_includes/topbar.html</code></p>\n\n        <div class=\"language-html highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n6\n7\n</pre></td> --><td class=\"rouge-code\"><pre>  - {% if paths.size == 0 or page.layout == 'home' %}\n  -   <span class=\"c\">&lt;!-- index page --&gt;</span>\n  + {% if paths.size == 0 %}\n  +   <span class=\"c\">&lt;!-- home page --&gt;</span>\n  ...\n  -           {% elsif page.layout == 'category' or page.layout == 'tag' %}\n  +           {% elsif page.layout == 'category' or page.layout == 'tag' or page.layout == 'home' %}\n</pre></td></tr></tbody></table></code></pre></div>        </div>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p>Replace <code class=\"language-plaintext highlighter-rouge\">page.layout == 'home'</code> with <code class=\"language-plaintext highlighter-rouge\">page.url == '/' or page.url == site.baseurl</code> if needed, including <code class=\"language-plaintext highlighter-rouge\">_layouts/page.html</code>, <code class=\"language-plaintext highlighter-rouge\">_includes/head.html</code>, <code class=\"language-plaintext highlighter-rouge\">/_includes/sidebar.html</code>, and <code class=\"language-plaintext highlighter-rouge\">_includes/topbar.html</code>.</p>\n  </li>\n  <li>\n    <p>(Optional) Modify your style in <code class=\"language-plaintext highlighter-rouge\">/_tabs/about.md</code>. For example, this demo we disable <code class=\"language-plaintext highlighter-rouge\">title</code>, <code class=\"language-plaintext highlighter-rouge\">post-meta</code> and <code class=\"language-plaintext highlighter-rouge\">tails</code> in the homepage by assigning bool values <code class=\"language-plaintext highlighter-rouge\">has_title</code>, <code class=\"language-plaintext highlighter-rouge\">has_meta</code> and <code class=\"language-plaintext highlighter-rouge\">has_tail</code> to skip related part in <code class=\"language-plaintext highlighter-rouge\">_layouts/page.html</code> and <code class=\"language-plaintext highlighter-rouge\">_layouts/post.html</code>.</p>\n  </li>\n</ol>\n",
          "url": "/blog/exchange-homepage-and-about/",
          
          "relUrl": "/blog/exchange-homepage-and-about/"
        }
      ,
        "17": {
          "doc": "Customize Your Jekyll Chirpy Theme",
          "title": "Customize Your Jekyll Chirpy Theme",
          "content": "<p><a href=\"https://github.com/cotes2020/jekyll-theme-chirpy\">Jekyll Chirpy Theme</a> is a highly customizable theme with a large number of users and a very complete ecology. You can reproduce or adjust the configuration according to the official <a href=\"https://github.com/cotes2020/jekyll-theme-chirpy/wiki\">wiki</a> to realize your own magic modification.</p>\n\n<p>This blog introduces some basic tutorials to customize your own Chirpy theme, suitable for those friends who are not satisfied with the Chirpy configuration and want more blogging functions. Welcome to <a href=\"https://github.com/JinchaoLove/jekyll-chirpy-demo/issues\">issue</a> or <a href=\"https://github.com/JinchaoLove/jekyll-chirpy-demo/pulls\">join us</a> to help others build blogs.</p>\n\n<ul>\n  <li>\n    <p><a href=\"/blog/exchange-homepage-and-about/\">Exchange Homepage and About</a></p>\n  </li>\n  <li>\n    <p><a href=\"https://nihil.cc/posts/use_valine/\">Replace Disqus with Valine for Discussion</a></p>\n  </li>\n</ul>\n\n",
          "url": "/blog/customize-jekyll-chirpy/",
          
          "relUrl": "/blog/customize-jekyll-chirpy/"
        }
      ,
        "18": {
          "doc": "Getting Started",
          "title": "Prerequisites",
          "content": "\n\n<p>Follow the instructions in the <a href=\"https://jekyllrb.com/docs/installation/\">Jekyll Docs</a> to complete the installation of the basic environment. <a href=\"https://git-scm.com/\">Git</a> also needs to be installed.</p>\n\n",
          "url": "/blog/getting-started/#prerequisites",
          
          "relUrl": "/blog/getting-started/#prerequisites"
        },
        "19": {
          "doc": "Getting Started",
          "title": "Installation",
          "content": "\n\n<h3 id=\"creating-a-new-site\">Creating a New Site</h3>\n\n<p>There are two ways to create a new repository for this theme:</p>\n\n<ul>\n  <li><a href=\"#option-1-using-the-chirpy-starter\"><strong>Using the Chirpy Starter</strong></a> - Easy to upgrade, isolates irrelevant project files so you can focus on writing.</li>\n  <li><a href=\"#option-2-github-fork\"><strong>GitHub Fork</strong></a> - Convenient for custom development, but difficult to upgrade. Unless you are familiar with Jekyll and are determined to tweak or contribute to this project, this approach is not recommended.</li>\n</ul>\n\n<h4 id=\"option-1-using-the-chirpy-starter\">Option 1. Using the Chirpy Starter</h4>\n\n<p>Sign in to GitHub and browse to <a href=\"https://github.com/cotes2020/chirpy-starter\"><strong>Chirpy Starter</strong></a>, click the button <kbd>Use this template</kbd> &gt; <kbd>Create a new repository</kbd>, and name the new repository <code class=\"language-plaintext highlighter-rouge\">USERNAME.github.io</code>, where <code class=\"language-plaintext highlighter-rouge\">USERNAME</code> represents your GitHub username.</p>\n\n<h4 id=\"option-2-github-fork\">Option 2. GitHub Fork</h4>\n\n<p>Sign in to GitHub to <a href=\"https://github.com/cotes2020/jekyll-theme-chirpy/fork\">fork <strong>Chirpy</strong></a>, and then rename it to <code class=\"language-plaintext highlighter-rouge\">USERNAME.github.io</code> (<code class=\"language-plaintext highlighter-rouge\">USERNAME</code> means your username).</p>\n\n<p>Next, clone your site to local machine. In order to build JavaScript files later, we need to install <a href=\"https://nodejs.org/\">Node.js</a>, and then run the tool:</p>\n\n<div class=\"language-console highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"go\">bash tools/init\n</span></pre></td></tr></tbody></table></code></pre></div></div>\n\n<blockquote class=\"prompt-info\">\n  <p>If you don’t want to deploy your site on GitHub Pages, append option <code class=\"language-plaintext highlighter-rouge\">--no-gh</code> at the end of the above command.</p>\n</blockquote>\n\n<p>The above command will:</p>\n\n<ol>\n  <li>Check out the code to the <a href=\"https://github.com/cotes2020/jekyll-theme-chirpy/tags\">latest tag</a> (to ensure the stability of your site: as the code for the default branch is under development).</li>\n  <li>Remove non-essential sample files and take care of GitHub-related files.</li>\n  <li>Build JavaScript files and export to <code class=\"language-plaintext filepath highlighter-rouge\">assets/js/dist/</code>, then make them tracked by Git.</li>\n  <li>Automatically create a new commit to save the changes above.</li>\n</ol>\n\n<h3 id=\"installing-dependencies\">Installing Dependencies</h3>\n\n<p>Before running local server for the first time, go to the root directory of your site and run:</p>\n\n<div class=\"language-console highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"go\">bundle\n</span></pre></td></tr></tbody></table></code></pre></div></div>\n\n",
          "url": "/blog/getting-started/#installation",
          
          "relUrl": "/blog/getting-started/#installation"
        },
        "20": {
          "doc": "Getting Started",
          "title": "Usage",
          "content": "\n\n<h3 id=\"configuration\">Configuration</h3>\n\n<p>Update the variables of <code class=\"language-plaintext filepath highlighter-rouge\">_config.yml</code> as needed. Some of them are typical options:</p>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">url</code></li>\n  <li><code class=\"language-plaintext highlighter-rouge\">avatar</code></li>\n  <li><code class=\"language-plaintext highlighter-rouge\">timezone</code></li>\n  <li><code class=\"language-plaintext highlighter-rouge\">lang</code></li>\n</ul>\n\n<h3 id=\"customizing-stylesheet\">Customizing Stylesheet</h3>\n\n<p>If you need to customize the stylesheet, copy the theme’s <code class=\"language-plaintext filepath highlighter-rouge\">assets/css/style.scss</code> to the same path on your Jekyll site, and then add the custom style at the end of it.</p>\n\n<p>Starting with version <code class=\"language-plaintext highlighter-rouge\">4.1.0</code>, if you want to overwrite the SASS variables defined in <code class=\"language-plaintext filepath highlighter-rouge\">_sass/addon/variables.scss</code>, copy the main sass file <code class=\"language-plaintext filepath highlighter-rouge\">_sass/jekyll-theme-chirpy.scss</code> into the <code class=\"language-plaintext filepath highlighter-rouge\">_sass</code> directory in your site’s source, then create a new file <code class=\"language-plaintext filepath highlighter-rouge\">_sass/variables-hook.scss</code> and assign new value.</p>\n\n<h3 id=\"customing-static-assets\">Customing Static Assets</h3>\n\n<p>Static assets configuration was introduced in version <code class=\"language-plaintext highlighter-rouge\">5.1.0</code>. The CDN of the static assets is defined by file <code class=\"language-plaintext filepath highlighter-rouge\">_data/origin/cors.yml</code>, and you can replace some of them according to the network conditions in the region where your website is published.</p>\n\n<p>Also, if you’d like to self-host the static assets, please refer to the <a href=\"https://github.com/cotes2020/chirpy-static-assets#readme\"><em>chirpy-static-assets</em></a>.</p>\n\n<h3 id=\"running-local-server\">Running Local Server</h3>\n\n<p>You may want to preview the site contents before publishing, so just run it by:</p>\n\n<div class=\"language-console highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"go\">bundle exec jekyll s\n</span></pre></td></tr></tbody></table></code></pre></div></div>\n\n<p>Or run the site on Docker with the following command:</p>\n\n<div class=\"language-console highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"go\">docker run -it --rm \\\n</span><span class=\"gp\">    --volume=\"$</span>PWD:/srv/jekyll<span class=\"s2\">\" </span><span class=\"se\">\\</span><span class=\"s2\">\n</span><span class=\"go\">    -p 4000:4000 jekyll/jekyll \\\n    jekyll serve\n</span></pre></td></tr></tbody></table></code></pre></div></div>\n\n<p>After a few seconds, the local service will be published at <em><a href=\"http://127.0.0.1:4000\">http://127.0.0.1:4000</a></em>.</p>\n\n",
          "url": "/blog/getting-started/#usage",
          
          "relUrl": "/blog/getting-started/#usage"
        },
        "21": {
          "doc": "Getting Started",
          "title": "Deployment",
          "content": "\n\n<p>Before the deployment begins, check out the file <code class=\"language-plaintext filepath highlighter-rouge\">_config.yml</code> and make sure the <code class=\"language-plaintext highlighter-rouge\">url</code> is configured correctly. Furthermore, if you prefer the <a href=\"https://help.github.com/en/github/working-with-github-pages/about-github-pages#types-of-github-pages-sites\"><strong>project site</strong></a> and don’t use a custom domain, or you want to visit your website with a base URL on a web server other than <strong>GitHub Pages</strong>, remember to change the <code class=\"language-plaintext highlighter-rouge\">baseurl</code> to your project name that starts with a slash, e.g, <code class=\"language-plaintext highlighter-rouge\">/project-name</code>.</p>\n\n<p>Now you can choose <em>ONE</em> of the following methods to deploy your Jekyll site.</p>\n\n<h3 id=\"deploy-by-using-github-actions\">Deploy by Using GitHub Actions</h3>\n\n<p>There are a few things to get ready for.</p>\n\n<ul>\n  <li>If you’re on the GitHub Free plan, keep your site repository public.</li>\n  <li>\n    <p>If you have committed <code class=\"language-plaintext filepath highlighter-rouge\">Gemfile.lock</code> to the repository, and your local machine is not running Linux, go the the root of your site and update the platform list of the lock-file:</p>\n\n    <div class=\"language-console highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"go\">bundle lock --add-platform x86_64-linux\n</span></pre></td></tr></tbody></table></code></pre></div>    </div>\n  </li>\n</ul>\n\n<p>Next, configure the <em>Pages</em> service.</p>\n\n<ol>\n  <li>\n    <p>Browse to your repository on GitHub. Select the tab <em>Settings</em>, then click <em>Pages</em> in the left navigation bar. Then, in the <strong>Source</strong> section (under <em>Build and deployment</em>), select <a href=\"https://docs.github.com/en/pages/getting-started-with-github-pages/configuring-a-publishing-source-for-your-github-pages-site#publishing-with-a-custom-github-actions-workflow\"><strong>GitHub Actions</strong></a> from the dropdown menu.<br />\n<img src=\"pages-source-light.png\" alt=\"Build source\" class=\"light border normal\" w=\"375\" h=\"140\" />\n<img src=\"pages-source-dark.png\" alt=\"Build source\" class=\"dark normal\" w=\"375\" h=\"140\" /></p>\n  </li>\n  <li>\n    <p>Push any commits to GitHub to trigger the <em>Actions</em> workflow. In the <em>Actions</em> tab of your repository, you should see the workflow <em>Build and Deploy</em> running. Once the build is complete and successful, the site will be deployed automatically.</p>\n  </li>\n</ol>\n\n<p>At this point, you can go to the URL indicated by GitHub to access your site.</p>\n\n<h3 id=\"manually-build-and-deploy\">Manually Build and Deploy</h3>\n\n<p>On self-hosted servers, you cannot enjoy the convenience of <strong>GitHub Actions</strong>. Therefore, you should build the site on your local machine and then upload the site files to the server.</p>\n\n<p>Go to the root of the source project, and build your site as follows:</p>\n\n<div class=\"language-console highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"go\">JEKYLL_ENV=production bundle exec jekyll b\n</span></pre></td></tr></tbody></table></code></pre></div></div>\n\n<p>Or build the site on Docker:</p>\n\n<div class=\"language-console highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"go\">docker run -it --rm \\\n    --env JEKYLL_ENV=production \\\n</span><span class=\"gp\">    --volume=\"$</span>PWD:/srv/jekyll<span class=\"s2\">\" </span><span class=\"se\">\\</span><span class=\"s2\">\n</span><span class=\"go\">    jekyll/jekyll \\\n    jekyll build\n</span></pre></td></tr></tbody></table></code></pre></div></div>\n\n<p>Unless you specified the output path, the generated site files will be placed in folder <code class=\"language-plaintext filepath highlighter-rouge\">_site</code> of the project’s root directory. Now you should upload those files to the target server.</p>\n\n",
          "url": "/blog/getting-started/#deployment",
          
          "relUrl": "/blog/getting-started/#deployment"
        },
        "22": {
          "doc": "Getting Started",
          "title": "Getting Started",
          "content": "",
          "url": "/blog/getting-started/",
          
          "relUrl": "/blog/getting-started/"
        }
      ,
        "23": {
          "doc": "Writing a New Post",
          "title": "Naming and Path",
          "content": "\n\n<p>Create a new file named <code class=\"language-plaintext filepath highlighter-rouge\">YYYY-MM-DD-TITLE.EXTENSION</code> and put it in the <code class=\"language-plaintext filepath highlighter-rouge\">_posts</code> of the root directory. Please note that the <code class=\"language-plaintext filepath highlighter-rouge\">EXTENSION</code> must be one of <code class=\"language-plaintext filepath highlighter-rouge\">md</code> and <code class=\"language-plaintext filepath highlighter-rouge\">markdown</code>. If you want to save time of creating files, please consider using the plugin <a href=\"https://github.com/jekyll/jekyll-compose\"><code class=\"language-plaintext highlighter-rouge\">Jekyll-Compose</code></a> to accomplish this.</p>\n\n",
          "url": "/blog/write-a-new-post/#naming-and-path",
          
          "relUrl": "/blog/write-a-new-post/#naming-and-path"
        },
        "24": {
          "doc": "Writing a New Post",
          "title": "Front Matter",
          "content": "\n\n<p>Basically, you need to fill the <a href=\"https://jekyllrb.com/docs/front-matter/\">Front Matter</a> as below at the top of the post:</p>\n\n<div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n6\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"nn\">---</span>\n<span class=\"na\">title</span><span class=\"pi\">:</span> <span class=\"s\">TITLE</span>\n<span class=\"na\">date</span><span class=\"pi\">:</span> <span class=\"s\">YYYY-MM-DD HH:MM:SS +/-TTTT</span>\n<span class=\"na\">categories</span><span class=\"pi\">:</span> <span class=\"pi\">[</span><span class=\"nv\">TOP_CATEGORIE</span><span class=\"pi\">,</span> <span class=\"nv\">SUB_CATEGORIE</span><span class=\"pi\">]</span>\n<span class=\"na\">tags</span><span class=\"pi\">:</span> <span class=\"pi\">[</span><span class=\"nv\">TAG</span><span class=\"pi\">]</span>     <span class=\"c1\"># TAG names should always be lowercase</span>\n<span class=\"nn\">---</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<blockquote class=\"prompt-tip\">\n  <p>The posts’ <em>layout</em> has been set to <code class=\"language-plaintext highlighter-rouge\">post</code> by default, so there is no need to add the variable <em>layout</em> in the Front Matter block.</p>\n</blockquote>\n\n<h3 id=\"timezone-of-date\">Timezone of Date</h3>\n\n<p>In order to accurately record the release date of a post, you should not only set up the <code class=\"language-plaintext highlighter-rouge\">timezone</code> of <code class=\"language-plaintext filepath highlighter-rouge\">_config.yml</code> but also provide the post’s timezone in variable <code class=\"language-plaintext highlighter-rouge\">date</code> of its Front Matter block. Format: <code class=\"language-plaintext highlighter-rouge\">+/-TTTT</code>, e.g. <code class=\"language-plaintext highlighter-rouge\">+0800</code>.</p>\n\n<h3 id=\"categories-and-tags\">Categories and Tags</h3>\n\n<p>The <code class=\"language-plaintext highlighter-rouge\">categories</code> of each post are designed to contain up to two elements, and the number of elements in <code class=\"language-plaintext highlighter-rouge\">tags</code> can be zero to infinity. For instance:</p>\n\n<div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"nn\">---</span>\n<span class=\"na\">categories</span><span class=\"pi\">:</span> <span class=\"pi\">[</span><span class=\"nv\">Animal</span><span class=\"pi\">,</span> <span class=\"nv\">Insect</span><span class=\"pi\">]</span>\n<span class=\"na\">tags</span><span class=\"pi\">:</span> <span class=\"pi\">[</span><span class=\"nv\">bee</span><span class=\"pi\">]</span>\n<span class=\"nn\">---</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<h3 id=\"author-information\">Author Information</h3>\n\n<p>The author information of the post usually does not need to be filled in the <em>Front Matter</em> , they will be obtained from variables <code class=\"language-plaintext highlighter-rouge\">social.name</code> and the first entry of <code class=\"language-plaintext highlighter-rouge\">social.links</code> of the configuration file by default. But you can also override it as follows:</p>\n\n<p>Adding author information in <code class=\"language-plaintext highlighter-rouge\">_data/authors.yml</code> (If your website doesn’t have this file, don’t hesitate to create one).</p>\n\n<div file=\"_data/authors.yml\" class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"na\">&lt;author_id&gt;</span><span class=\"pi\">:</span>\n  <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">&lt;full name&gt;</span>\n  <span class=\"na\">twitter</span><span class=\"pi\">:</span> <span class=\"s\">&lt;twitter_of_author&gt;</span>\n  <span class=\"na\">url</span><span class=\"pi\">:</span> <span class=\"s\">&lt;homepage_of_author&gt;</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<p>And then use <code class=\"language-plaintext highlighter-rouge\">author</code> to specify a single entry or <code class=\"language-plaintext highlighter-rouge\">authors</code> to specify multiple entries:</p>\n\n<div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"nn\">---</span>\n<span class=\"na\">author</span><span class=\"pi\">:</span> <span class=\"s\">&lt;author_id&gt;</span>                     <span class=\"c1\"># for single entry</span>\n<span class=\"c1\"># or</span>\n<span class=\"na\">authors</span><span class=\"pi\">:</span> <span class=\"pi\">[</span><span class=\"nv\">&lt;author1_id&gt;</span><span class=\"pi\">,</span> <span class=\"nv\">&lt;author2_id&gt;</span><span class=\"pi\">]</span>   <span class=\"c1\"># for multiple entries</span>\n<span class=\"nn\">---</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<p>Having said that, the key <code class=\"language-plaintext highlighter-rouge\">author</code> can also identify multiple entries.</p>\n\n<blockquote class=\"prompt-info\">\n  <p>The benefit of reading the author information from the file <code class=\"language-plaintext filepath highlighter-rouge\">_data/authors.yml</code> is that the page will have the meta tag <code class=\"language-plaintext highlighter-rouge\">twitter:creator</code>, which enriches the <a href=\"https://developer.twitter.com/en/docs/twitter-for-websites/cards/guides/getting-started#card-and-content-attribution\">Twitter Cards</a> and is good for SEO.</p>\n</blockquote>\n\n",
          "url": "/blog/write-a-new-post/#front-matter",
          
          "relUrl": "/blog/write-a-new-post/#front-matter"
        },
        "25": {
          "doc": "Writing a New Post",
          "title": "Table of Contents",
          "content": "\n\n<p>By default, the <strong>T</strong>able <strong>o</strong>f <strong>C</strong>ontents (TOC) is displayed on the right panel of the post. If you want to turn it off globally, go to <code class=\"language-plaintext filepath highlighter-rouge\">_config.yml</code> and set the value of variable <code class=\"language-plaintext highlighter-rouge\">toc</code> to <code class=\"language-plaintext highlighter-rouge\">false</code>. If you want to turn off TOC for a specific post, add the following to the post’s <a href=\"https://jekyllrb.com/docs/front-matter/\">Front Matter</a>:</p>\n\n<div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"nn\">---</span>\n<span class=\"na\">toc</span><span class=\"pi\">:</span> <span class=\"kc\">false</span>\n<span class=\"nn\">---</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n",
          "url": "/blog/write-a-new-post/#table-of-contents",
          
          "relUrl": "/blog/write-a-new-post/#table-of-contents"
        },
        "26": {
          "doc": "Writing a New Post",
          "title": "Comments",
          "content": "\n\n<p>The global switch of comments is defined by variable <code class=\"language-plaintext highlighter-rouge\">comments.active</code> in the file <code class=\"language-plaintext filepath highlighter-rouge\">_config.yml</code>. After selecting a comment system for this variable, comments will be turned on for all posts.</p>\n\n<p>If you want to close the comment for a specific post, add the following to the <strong>Front Matter</strong> of the post:</p>\n\n<div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"nn\">---</span>\n<span class=\"na\">comments</span><span class=\"pi\">:</span> <span class=\"kc\">false</span>\n<span class=\"nn\">---</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n",
          "url": "/blog/write-a-new-post/#comments",
          
          "relUrl": "/blog/write-a-new-post/#comments"
        },
        "27": {
          "doc": "Writing a New Post",
          "title": "Mathematics",
          "content": "\n\n<p>For website performance reasons, the mathematical feature won’t be loaded by default. But it can be enabled by:</p>\n\n<div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"nn\">---</span>\n<span class=\"na\">math</span><span class=\"pi\">:</span> <span class=\"kc\">true</span>\n<span class=\"nn\">---</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<p>After enabling the mathematical feature, you can add math equations with the following syntax:</p>\n\n<ul>\n  <li><strong>Block math</strong> should be added with <code class=\"language-plaintext highlighter-rouge\">$$ math $$</code> with <strong>mandatory</strong> blank lines before and after <code class=\"language-plaintext highlighter-rouge\">$$</code>\n    <ul>\n      <li><strong>Inserting equation numbering</strong> should be added with <code class=\"language-plaintext highlighter-rouge\">$$\\begin{equation} math \\end{equation}$$</code></li>\n      <li><strong>Referencing equation numbering</strong> should be done with <code class=\"language-plaintext highlighter-rouge\">\\label{eq:label_name}</code> in the equation block and <code class=\"language-plaintext highlighter-rouge\">\\eqref{eq:label_name}</code> inline with text (see example below)</li>\n    </ul>\n  </li>\n  <li><strong>Inline math</strong> (in lines) should be added with <code class=\"language-plaintext highlighter-rouge\">$$ math $$</code> without any blank line before or after <code class=\"language-plaintext highlighter-rouge\">$$</code></li>\n  <li><strong>Inline math</strong> (in lists) should be added with <code class=\"language-plaintext highlighter-rouge\">\\$$ math $$</code></li>\n</ul>\n\n<div class=\"language-markdown highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"c\">&lt;!-- Block math, keep all blank lines --&gt;</span>\n\n$$\nLaTeX_math_expression\n$$\n\n<span class=\"c\">&lt;!-- Equation numbering, keep all blank lines  --&gt;</span>\n\n$$\n<span class=\"se\">\\b</span>egin{equation}\n  LaTeX_math_expression\n  <span class=\"se\">\\l</span>abel{eq:label_name}\n<span class=\"se\">\\e</span>nd{equation}\n$$\n\nCan be referenced as <span class=\"se\">\\e</span>qref{eq:label_name}.\n\n<span class=\"c\">&lt;!-- Inline math in lines, NO blank lines --&gt;</span>\n\n\"Lorem ipsum dolor sit amet, $$ LaTeX_math_expression $$ consectetur adipiscing elit.\"\n\n<span class=\"c\">&lt;!-- Inline math in lists, escape the first `$` --&gt;</span>\n<span class=\"p\">\n1.</span> <span class=\"se\">\\$</span>$ LaTeX_math_expression $$\n<span class=\"p\">2.</span> <span class=\"se\">\\$</span>$ LaTeX_math_expression $$\n<span class=\"p\">3.</span> <span class=\"se\">\\$</span>$ LaTeX_math_expression $$\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n",
          "url": "/blog/write-a-new-post/#mathematics",
          
          "relUrl": "/blog/write-a-new-post/#mathematics"
        },
        "28": {
          "doc": "Writing a New Post",
          "title": "Mermaid",
          "content": "\n\n<p><a href=\"https://github.com/mermaid-js/mermaid\"><strong>Mermaid</strong></a> is a great diagram generation tool. To enable it on your post, add the following to the YAML block:</p>\n\n<div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"nn\">---</span>\n<span class=\"na\">mermaid</span><span class=\"pi\">:</span> <span class=\"kc\">true</span>\n<span class=\"nn\">---</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<p>Then you can use it like other markdown languages: surround the graph code with <code class=\"language-plaintext highlighter-rouge\">```mermaid</code> and <code class=\"language-plaintext highlighter-rouge\">```</code>.</p>\n\n",
          "url": "/blog/write-a-new-post/#mermaid",
          
          "relUrl": "/blog/write-a-new-post/#mermaid"
        },
        "29": {
          "doc": "Writing a New Post",
          "title": "Images",
          "content": "\n\n<h3 id=\"caption\">Caption</h3>\n\n<p>Add italics to the next line of an image, then it will become the caption and appear at the bottom of the image:</p>\n\n<div class=\"language-markdown nolineno highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"p\">![</span><span class=\"nv\">img-description</span><span class=\"p\">](</span><span class=\"sx\">/path/to/image</span><span class=\"p\">)</span>\n<span class=\"ge\">_Image Caption_</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<h3 id=\"size\">Size</h3>\n\n<p>In order to prevent the page content layout from shifting when the image is loaded, we should set the width and height for each image.</p>\n\n<div class=\"language-markdown nolineno highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"p\">![</span><span class=\"nv\">Desktop View</span><span class=\"p\">](</span><span class=\"sx\">/assets/img/sample/mockup.png</span><span class=\"p\">)</span>{: width=\"700\" height=\"400\" }\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<blockquote class=\"prompt-info\">\n  <p>For an SVG, you have to at least specify its <em>width</em>, otherwise it won’t be rendered.</p>\n</blockquote>\n\n<p>Starting from <em>Chirpy v5.0.0</em>, <code class=\"language-plaintext highlighter-rouge\">height</code> and <code class=\"language-plaintext highlighter-rouge\">width</code> support abbreviations (<code class=\"language-plaintext highlighter-rouge\">height</code> → <code class=\"language-plaintext highlighter-rouge\">h</code>, <code class=\"language-plaintext highlighter-rouge\">width</code> → <code class=\"language-plaintext highlighter-rouge\">w</code>). The following example has the same effect as the above:</p>\n\n<div class=\"language-markdown nolineno highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"p\">![</span><span class=\"nv\">Desktop View</span><span class=\"p\">](</span><span class=\"sx\">/assets/img/sample/mockup.png</span><span class=\"p\">)</span>{: w=\"700\" h=\"400\" }\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<h3 id=\"position\">Position</h3>\n\n<p>By default, the image is centered, but you can specify the position by using one of the classes <code class=\"language-plaintext highlighter-rouge\">normal</code>, <code class=\"language-plaintext highlighter-rouge\">left</code>, and <code class=\"language-plaintext highlighter-rouge\">right</code>.</p>\n\n<blockquote class=\"prompt-warning\">\n  <p>Once the position is specified, the image caption should not be added.</p>\n</blockquote>\n\n<ul>\n  <li>\n    <p><strong>Normal position</strong></p>\n\n    <p>Image will be left aligned in below sample:</p>\n\n    <div class=\"language-markdown nolineno highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"p\">![</span><span class=\"nv\">Desktop View</span><span class=\"p\">](</span><span class=\"sx\">/assets/img/sample/mockup.png</span><span class=\"p\">)</span>{: .normal }\n</pre></td></tr></tbody></table></code></pre></div>    </div>\n  </li>\n  <li>\n    <p><strong>Float to the left</strong></p>\n\n    <div class=\"language-markdown nolineno highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"p\">![</span><span class=\"nv\">Desktop View</span><span class=\"p\">](</span><span class=\"sx\">/assets/img/sample/mockup.png</span><span class=\"p\">)</span>{: .left }\n</pre></td></tr></tbody></table></code></pre></div>    </div>\n  </li>\n  <li>\n    <p><strong>Float to the right</strong></p>\n\n    <div class=\"language-markdown nolineno highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"p\">![</span><span class=\"nv\">Desktop View</span><span class=\"p\">](</span><span class=\"sx\">/assets/img/sample/mockup.png</span><span class=\"p\">)</span>{: .right }\n</pre></td></tr></tbody></table></code></pre></div>    </div>\n  </li>\n</ul>\n\n<h3 id=\"darklight-mode\">Dark/Light mode</h3>\n\n<p>You can make images follow theme preferences in dark/light mode. This requires you to prepare two images, one for dark mode and one for light mode, and then assign them a specific class (<code class=\"language-plaintext highlighter-rouge\">dark</code> or <code class=\"language-plaintext highlighter-rouge\">light</code>):</p>\n\n<div class=\"language-markdown highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"p\">![</span><span class=\"nv\">Light mode only</span><span class=\"p\">](</span><span class=\"sx\">/path/to/light-mode.png</span><span class=\"p\">)</span>{: .light }\n<span class=\"p\">![</span><span class=\"nv\">Dark mode only</span><span class=\"p\">](</span><span class=\"sx\">/path/to/dark-mode.png</span><span class=\"p\">)</span>{: .dark }\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<h3 id=\"shadow\">Shadow</h3>\n\n<p>The screenshots of the program window can be considered to show the shadow effect:</p>\n\n<div class=\"language-markdown nolineno highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"p\">![</span><span class=\"nv\">Desktop View</span><span class=\"p\">](</span><span class=\"sx\">/assets/img/sample/mockup.png</span><span class=\"p\">)</span>{: .shadow }\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<h3 id=\"image-path\">Image Path</h3>\n\n<p>When a post contains many images, it will be a time-consuming task to repeatedly define the path of the images. To solve this, we can define this path in the YAML block of the post:</p>\n\n<div class=\"language-yml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"nn\">---</span>\n<span class=\"na\">img_path</span><span class=\"pi\">:</span> <span class=\"s\">/img/path/</span>\n<span class=\"nn\">---</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<p>And then, the image source of Markdown can write the file name directly:</p>\n\n<div class=\"language-md nolineno highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"p\">![</span><span class=\"nv\">The flower</span><span class=\"p\">](</span><span class=\"sx\">flower.png</span><span class=\"p\">)</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<p>The output will be:</p>\n\n<div class=\"language-html nolineno highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"nt\">&lt;img</span> <span class=\"na\">src=</span><span class=\"s\">\"/img/path/flower.png\"</span> <span class=\"na\">alt=</span><span class=\"s\">\"The flower\"</span> <span class=\"nt\">/&gt;</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<h3 id=\"preview-image\">Preview Image</h3>\n\n<p>If you want to add an image at the top of the post, please provide an image with a resolution of <code class=\"language-plaintext highlighter-rouge\">1200 x 630</code>. Please note that if the image aspect ratio does not meet <code class=\"language-plaintext highlighter-rouge\">1.91 : 1</code>, the image will be scaled and cropped.</p>\n\n<p>Knowing these prerequisites, you can start setting the image’s attribute:</p>\n\n<div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"nn\">---</span>\n<span class=\"na\">image</span><span class=\"pi\">:</span>\n  <span class=\"na\">path</span><span class=\"pi\">:</span> <span class=\"s\">/path/to/image</span>\n  <span class=\"na\">alt</span><span class=\"pi\">:</span> <span class=\"s\">image alternative text</span>\n<span class=\"nn\">---</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<p>Note that the <a href=\"#image-path\"><code class=\"language-plaintext highlighter-rouge\">img_path</code></a> can also be passed to the preview image, that is, when it has been set, the attribute <code class=\"language-plaintext highlighter-rouge\">path</code> only needs the image file name.</p>\n\n<p>For simple use, you can also just use <code class=\"language-plaintext highlighter-rouge\">image</code> to define the path.</p>\n\n<div class=\"language-yml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"nn\">---</span>\n<span class=\"na\">image</span><span class=\"pi\">:</span> <span class=\"s\">/path/to/image</span>\n<span class=\"nn\">---</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<h3 id=\"lqip\">LQIP</h3>\n\n<p>For preview images:</p>\n\n<div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"nn\">---</span>\n<span class=\"na\">image</span><span class=\"pi\">:</span>\n  <span class=\"na\">lqip</span><span class=\"pi\">:</span> <span class=\"s\">/path/to/lqip-file</span> <span class=\"c1\"># or base64 URI</span>\n<span class=\"nn\">---</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<blockquote>\n  <p>You can observe LQIP in the preview image of post <a href=\"https://chirpy-img.netlify.app/posts/text-and-typography/\"><em>Text and Typography</em></a>.</p>\n</blockquote>\n\n<p>For normal images:</p>\n\n<div class=\"language-markdown nolineno highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"p\">![</span><span class=\"nv\">Image description</span><span class=\"p\">](</span><span class=\"sx\">/path/to/image</span><span class=\"p\">)</span>{: lqip=\"/path/to/lqip-file\" }\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n",
          "url": "/blog/write-a-new-post/#images",
          
          "relUrl": "/blog/write-a-new-post/#images"
        },
        "30": {
          "doc": "Writing a New Post",
          "title": "Pinned Posts",
          "content": "\n\n<p>You can pin one or more posts to the top of the home page, and the fixed posts are sorted in reverse order according to their release date. Enable by:</p>\n\n<div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"nn\">---</span>\n<span class=\"na\">pin</span><span class=\"pi\">:</span> <span class=\"kc\">true</span>\n<span class=\"nn\">---</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n",
          "url": "/blog/write-a-new-post/#pinned-posts",
          
          "relUrl": "/blog/write-a-new-post/#pinned-posts"
        },
        "31": {
          "doc": "Writing a New Post",
          "title": "Prompts",
          "content": "\n\n<p>There are several types of prompts: <code class=\"language-plaintext highlighter-rouge\">tip</code>, <code class=\"language-plaintext highlighter-rouge\">info</code>, <code class=\"language-plaintext highlighter-rouge\">warning</code>, and <code class=\"language-plaintext highlighter-rouge\">danger</code>. They can be generated by adding the class <code class=\"language-plaintext highlighter-rouge\">prompt-{type}</code> to the blockquote. For example, define a prompt of type <code class=\"language-plaintext highlighter-rouge\">info</code> as follows:</p>\n\n<div class=\"language-md nolineno highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"gt\">&gt; Example line for prompt.</span>\n{: .prompt-info }\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n",
          "url": "/blog/write-a-new-post/#prompts",
          
          "relUrl": "/blog/write-a-new-post/#prompts"
        },
        "32": {
          "doc": "Writing a New Post",
          "title": "Syntax",
          "content": "\n\n<h3 id=\"inline-code\">Inline Code</h3>\n\n<div class=\"language-md nolineno highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"sb\">`inline code part`</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<h3 id=\"filepath-hightlight\">Filepath Hightlight</h3>\n\n<div class=\"language-md nolineno highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"sb\">`/path/to/a/file.extend`</span>{: .filepath}\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<h3 id=\"code-block\">Code Block</h3>\n\n<p>Markdown symbols <code class=\"language-plaintext highlighter-rouge\">```</code> can easily create a code block as follows:</p>\n\n<div class=\"language-md highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"p\">```</span><span class=\"nl\">\n</span>This is a plaintext code snippet.\n<span class=\"p\">```</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<h4 id=\"specifying-language\">Specifying Language</h4>\n\n<p>Using <code class=\"language-plaintext highlighter-rouge\">```{language}</code> you will get a code block with syntax highlight:</p>\n\n<div class=\"language-markdown highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"p\">```</span><span class=\"nl\">yaml\n</span><span class=\"na\">key</span><span class=\"pi\">:</span> <span class=\"s\">value</span>\n<span class=\"p\">```</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<blockquote class=\"prompt-danger\">\n  <p>The Jekyll tag <code class=\"language-plaintext highlighter-rouge\">{% highlight %}</code> is not compatible with this theme.</p>\n</blockquote>\n\n<h4 id=\"line-number\">Line Number</h4>\n\n<p>By default, all languages except <code class=\"language-plaintext highlighter-rouge\">plaintext</code>, <code class=\"language-plaintext highlighter-rouge\">console</code>, and <code class=\"language-plaintext highlighter-rouge\">terminal</code> will display line numbers. When you want to hide the line number of a code block, add the class <code class=\"language-plaintext highlighter-rouge\">nolineno</code> to it:</p>\n\n<div class=\"language-markdown highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"p\">```</span><span class=\"nl\">shell\n</span><span class=\"nb\">echo</span> <span class=\"s1\">'No more line numbers!'</span>\n<span class=\"p\">```</span>\n{: .nolineno }\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<h4 id=\"specifying-the-filename\">Specifying the Filename</h4>\n\n<p>You may have noticed that the code language will be displayed at the top of the code block. If you want to replace it with the file name, you can add the attribute <code class=\"language-plaintext highlighter-rouge\">file</code> to achieve this:</p>\n\n<div class=\"language-markdown highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"p\">```</span><span class=\"nl\">shell\n</span><span class=\"c\"># content</span>\n<span class=\"p\">```</span>\n{: file=\"path/to/file\" }\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<h4 id=\"liquid-codes\">Liquid Codes</h4>\n\n<p>If you want to display the <strong>Liquid</strong> snippet, surround the liquid code with <code class=\"language-plaintext highlighter-rouge\">{% raw %}</code> and <code class=\"language-plaintext highlighter-rouge\">{% endraw %}</code>:</p>\n\n<div class=\"language-markdown highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n5\n6\n7\n</pre></td> --><td class=\"rouge-code\"><pre>{% raw %}\n<span class=\"p\">```</span><span class=\"nl\">liquid\n</span><span class=\"cp\">{%</span><span class=\"w\"> </span><span class=\"nt\">if</span><span class=\"w\"> </span><span class=\"nv\">product</span><span class=\"p\">.</span><span class=\"nv\">title</span><span class=\"w\"> </span><span class=\"ow\">contains</span><span class=\"w\"> </span><span class=\"s1\">'Pack'</span><span class=\"w\"> </span><span class=\"cp\">%}</span>\n  This product's title contains the word Pack.\n<span class=\"cp\">{%</span><span class=\"w\"> </span><span class=\"nt\">endif</span><span class=\"w\"> </span><span class=\"cp\">%}</span>\n<span class=\"p\">```</span>\n{% endraw %}\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<p>Or adding <code class=\"language-plaintext highlighter-rouge\">render_with_liquid: false</code> (Requires Jekyll 4.0 or higher) to the post’s YAML block.</p>\n\n",
          "url": "/blog/write-a-new-post/#syntax",
          
          "relUrl": "/blog/write-a-new-post/#syntax"
        },
        "33": {
          "doc": "Writing a New Post",
          "title": "Videos",
          "content": "\n\n<p>You can embed a video with the following syntax:</p>\n\n<div class=\"language-liquid highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"cp\">{%</span><span class=\"w\"> </span><span class=\"nt\">include</span><span class=\"w\"> </span>embed/{Platform}.html<span class=\"w\"> </span><span class=\"na\">id</span><span class=\"o\">=</span><span class=\"s1\">'{ID}'</span><span class=\"w\"> </span><span class=\"cp\">%}</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<p>Where <code class=\"language-plaintext highlighter-rouge\">Platform</code> is the lowercase of the platform name, and <code class=\"language-plaintext highlighter-rouge\">ID</code> is the video ID.</p>\n\n<p>The following table shows how to get the two parameters we need in a given video URL, and you can also know the currently supported video platforms.</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>Video URL</th>\n      <th>Platform</th>\n      <th style=\"text-align: left\">ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td><a href=\"https://www.youtube.com/watch?v=H-B46URT4mg\">https://www.<strong>youtube</strong>.com/watch?v=<strong>H-B46URT4mg</strong></a></td>\n      <td><code class=\"language-plaintext highlighter-rouge\">youtube</code></td>\n      <td style=\"text-align: left\"><code class=\"language-plaintext highlighter-rouge\">H-B46URT4mg</code></td>\n    </tr>\n    <tr>\n      <td><a href=\"https://www.twitch.tv/videos/1634779211\">https://www.<strong>twitch</strong>.tv/videos/<strong>1634779211</strong></a></td>\n      <td><code class=\"language-plaintext highlighter-rouge\">twitch</code></td>\n      <td style=\"text-align: left\"><code class=\"language-plaintext highlighter-rouge\">1634779211</code></td>\n    </tr>\n    <tr>\n      <td><a href=\"https://www.bilibili.com/video/BV1Q44y1B7Wf\">https://www.<strong>bilibili</strong>.com/video/<strong>BV1Q44y1B7Wf</strong></a></td>\n      <td><code class=\"language-plaintext highlighter-rouge\">bilibili</code></td>\n      <td style=\"text-align: left\"><code class=\"language-plaintext highlighter-rouge\">BV1Q44y1B7Wf</code></td>\n    </tr>\n  </tbody>\n</table>\n\n",
          "url": "/blog/write-a-new-post/#videos",
          
          "relUrl": "/blog/write-a-new-post/#videos"
        },
        "34": {
          "doc": "Writing a New Post",
          "title": "Learn More",
          "content": "\n\n<p>For more knowledge about Jekyll posts, visit the <a href=\"https://jekyllrb.com/docs/posts/\">Jekyll Docs: Posts</a>.</p>\n",
          "url": "/blog/write-a-new-post/#learn-more",
          
          "relUrl": "/blog/write-a-new-post/#learn-more"
        },
        "35": {
          "doc": "Writing a New Post",
          "title": "Writing a New Post",
          "content": "<p>This tutorial will guide you how to write a post in the <em>Chirpy</em> template, and it’s worth reading even if you’ve used Jekyll before, as many features require specific variables to be set.</p>\n\n",
          "url": "/blog/write-a-new-post/",
          
          "relUrl": "/blog/write-a-new-post/"
        }
      ,
        "36": {
          "doc": "Text and Typography",
          "title": "Headings",
          "content": "\n\n",
          "url": "/blog/text-and-typography/#headings",
          
          "relUrl": "/blog/text-and-typography/#headings"
        },
        "37": {
          "doc": "Text and Typography",
          "title": "H1 - heading",
          "content": "\n\n",
          "url": "/blog/text-and-typography/#h1---heading",
          
          "relUrl": "/blog/text-and-typography/#h1---heading"
        },
        "38": {
          "doc": "Text and Typography",
          "title": "H2 - heading",
          "content": "\n\n<h3 data-toc-skip=\"\" class=\"mt-4 mb-0\" id=\"h3---heading\">H3 - heading</h3>\n\n<h4 data-toc-skip=\"\" class=\"mt-4\" id=\"h4---heading\">H4 - heading</h4>\n\n",
          "url": "/blog/text-and-typography/#h2---heading",
          
          "relUrl": "/blog/text-and-typography/#h2---heading"
        },
        "39": {
          "doc": "Text and Typography",
          "title": "Paragraph",
          "content": "\n\n<p>Quisque egestas convallis ipsum, ut sollicitudin risus tincidunt a. Maecenas interdum malesuada egestas. Duis consectetur porta risus, sit amet vulputate urna facilisis ac. Phasellus semper dui non purus ultrices sodales. Aliquam ante lorem, ornare a feugiat ac, finibus nec mauris. Vivamus ut tristique nisi. Sed vel leo vulputate, efficitur risus non, posuere mi. Nullam tincidunt bibendum rutrum. Proin commodo ornare sapien. Vivamus interdum diam sed sapien blandit, sit amet aliquam risus mattis. Nullam arcu turpis, mollis quis laoreet at, placerat id nibh. Suspendisse venenatis eros eros.</p>\n\n",
          "url": "/blog/text-and-typography/#paragraph",
          
          "relUrl": "/blog/text-and-typography/#paragraph"
        },
        "40": {
          "doc": "Text and Typography",
          "title": "Lists",
          "content": "\n\n<h3 id=\"ordered-list\">Ordered list</h3>\n\n<ol>\n  <li>Firstly</li>\n  <li>Secondly</li>\n  <li>Thirdly</li>\n</ol>\n\n<h3 id=\"unordered-list\">Unordered list</h3>\n\n<ul>\n  <li>Chapter\n    <ul>\n      <li>Section\n        <ul>\n          <li>Paragraph</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n</ul>\n\n<h3 id=\"todo-list\">ToDo list</h3>\n\n<ul class=\"task-list\">\n  <li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" disabled=\"disabled\" />Job\n    <ul class=\"task-list\">\n      <li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" disabled=\"disabled\" checked=\"checked\" />Step 1</li>\n      <li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" disabled=\"disabled\" checked=\"checked\" />Step 2</li>\n      <li class=\"task-list-item\"><input type=\"checkbox\" class=\"task-list-item-checkbox\" disabled=\"disabled\" />Step 3</li>\n    </ul>\n  </li>\n</ul>\n\n<h3 id=\"description-list\">Description list</h3>\n\n<dl>\n  <dt>Sun</dt>\n  <dd>the star around which the earth orbits</dd>\n  <dt>Moon</dt>\n  <dd>the natural satellite of the earth, visible by reflected light from the sun</dd>\n</dl>\n\n",
          "url": "/blog/text-and-typography/#lists",
          
          "relUrl": "/blog/text-and-typography/#lists"
        },
        "41": {
          "doc": "Text and Typography",
          "title": "Block Quote",
          "content": "\n\n<blockquote>\n  <p>This line shows the <em>block quote</em>.</p>\n</blockquote>\n\n",
          "url": "/blog/text-and-typography/#block-quote",
          
          "relUrl": "/blog/text-and-typography/#block-quote"
        },
        "42": {
          "doc": "Text and Typography",
          "title": "Prompts",
          "content": "\n\n<blockquote class=\"prompt-tip\">\n  <p>An example showing the <code class=\"language-plaintext highlighter-rouge\">tip</code> type prompt.</p>\n</blockquote>\n\n<blockquote class=\"prompt-info\">\n  <p>An example showing the <code class=\"language-plaintext highlighter-rouge\">info</code> type prompt.</p>\n</blockquote>\n\n<blockquote class=\"prompt-warning\">\n  <p>An example showing the <code class=\"language-plaintext highlighter-rouge\">warning</code> type prompt.</p>\n</blockquote>\n\n<blockquote class=\"prompt-danger\">\n  <p>An example showing the <code class=\"language-plaintext highlighter-rouge\">danger</code> type prompt.</p>\n</blockquote>\n\n",
          "url": "/blog/text-and-typography/#prompts",
          
          "relUrl": "/blog/text-and-typography/#prompts"
        },
        "43": {
          "doc": "Text and Typography",
          "title": "Tables",
          "content": "\n\n<table>\n  <thead>\n    <tr>\n      <th style=\"text-align: left\">Company</th>\n      <th style=\"text-align: left\">Contact</th>\n      <th style=\"text-align: right\">Country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td style=\"text-align: left\">Alfreds Futterkiste</td>\n      <td style=\"text-align: left\">Maria Anders</td>\n      <td style=\"text-align: right\">Germany</td>\n    </tr>\n    <tr>\n      <td style=\"text-align: left\">Island Trading</td>\n      <td style=\"text-align: left\">Helen Bennett</td>\n      <td style=\"text-align: right\">UK</td>\n    </tr>\n    <tr>\n      <td style=\"text-align: left\">Magazzini Alimentari Riuniti</td>\n      <td style=\"text-align: left\">Giovanni Rovelli</td>\n      <td style=\"text-align: right\">Italy</td>\n    </tr>\n  </tbody>\n</table>\n\n",
          "url": "/blog/text-and-typography/#tables",
          
          "relUrl": "/blog/text-and-typography/#tables"
        },
        "44": {
          "doc": "Text and Typography",
          "title": "Links",
          "content": "\n\n<p><a href=\"http://127.0.0.1:4000\">http://127.0.0.1:4000</a></p>\n\n",
          "url": "/blog/text-and-typography/#links",
          
          "relUrl": "/blog/text-and-typography/#links"
        },
        "45": {
          "doc": "Text and Typography",
          "title": "Footnote",
          "content": "\n\n<p>Click the hook will locate the footnote<sup id=\"fnref:footnote\" role=\"doc-noteref\"><a href=\"#fn:footnote\" class=\"footnote\" rel=\"footnote\">1</a></sup>, and here is another footnote<sup id=\"fnref:fn-nth-2\" role=\"doc-noteref\"><a href=\"#fn:fn-nth-2\" class=\"footnote\" rel=\"footnote\">2</a></sup>.</p>\n\n",
          "url": "/blog/text-and-typography/#footnote",
          
          "relUrl": "/blog/text-and-typography/#footnote"
        },
        "46": {
          "doc": "Text and Typography",
          "title": "Inline code",
          "content": "\n\n<p>This is an example of <code class=\"language-plaintext highlighter-rouge\">Inline Code</code>.</p>\n\n",
          "url": "/blog/text-and-typography/#inline-code",
          
          "relUrl": "/blog/text-and-typography/#inline-code"
        },
        "47": {
          "doc": "Text and Typography",
          "title": "Filepath",
          "content": "\n\n<p>Here is the <code class=\"language-plaintext filepath highlighter-rouge\">/path/to/the/file.extend</code>.</p>\n\n",
          "url": "/blog/text-and-typography/#filepath",
          
          "relUrl": "/blog/text-and-typography/#filepath"
        },
        "48": {
          "doc": "Text and Typography",
          "title": "Code blocks",
          "content": "\n\n<h3 id=\"common\">Common</h3>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n</pre></td> --><td class=\"rouge-code\"><pre>This is a common code snippet, without syntax highlight and line number.\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<h3 id=\"specific-language\">Specific Language</h3>\n\n<div class=\"language-bash highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n4\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"k\">if</span> <span class=\"o\">[</span> <span class=\"nv\">$?</span> <span class=\"nt\">-ne</span> 0 <span class=\"o\">]</span><span class=\"p\">;</span> <span class=\"k\">then\n  </span><span class=\"nb\">echo</span> <span class=\"s2\">\"The command was not successful.\"</span><span class=\"p\">;</span>\n  <span class=\"c\">#do the needful / exit</span>\n<span class=\"k\">fi</span><span class=\"p\">;</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<h3 id=\"specific-filename\">Specific filename</h3>\n\n<div file=\"_sass/jekyll-theme-chirpy.scss\" class=\"language-sass highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><table class=\"rouge-table\"><tbody><tr><!-- <td class=\"rouge-gutter gl\"><pre class=\"lineno\">1\n2\n3\n</pre></td> --><td class=\"rouge-code\"><pre><span class=\"k\">@import</span>\n  <span class=\"s2\">\"colors/light-typography\"</span><span class=\"o\">,</span>\n  <span class=\"s2\">\"colors/dark-typography\"</span><span class=\"o\">;</span>\n</pre></td></tr></tbody></table></code></pre></div></div>\n\n<h3 id=\"jupyter-notebook\">Jupyter notebook</h3>\n\n<div\n  class=\"jupyter-notebook\"\n  style=\"position: relative; width: 100%; margin: 0 auto;\">\n  <div class=\"jupyter-notebook-iframe-container\">\n    <iframe\n      src=\"/assets/jupyter/blog.ipynb.html\"\n      style=\"position: absolute; top: 0; left: 0; border-style: none;\"\n      width=\"100%\"\n      height=\"100%\"\n      onload=\"this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'\"></iframe>\n  </div>\n</div>\n\n\n",
          "url": "/blog/text-and-typography/#code-blocks",
          
          "relUrl": "/blog/text-and-typography/#code-blocks"
        },
        "49": {
          "doc": "Text and Typography",
          "title": "Mathematics",
          "content": "\n\n<p>The mathematics powered by <a href=\"https://www.mathjax.org/\"><strong>MathJax</strong></a>:</p>\n\n\\[\\begin{equation}\n  \\sum_{n=1}^\\infty 1/n^2 = \\frac{\\pi^2}{6}\n  \\label{eq:series}\n\\end{equation}\\]\n\n<p>We can reference the equation as \\eqref{eq:series}.</p>\n\n<p>When $a \\ne 0$, there are two solutions to $ax^2 + bx + c = 0$ and they are</p>\n\n\\[x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}\\]\n\n",
          "url": "/blog/text-and-typography/#mathematics",
          
          "relUrl": "/blog/text-and-typography/#mathematics"
        },
        "50": {
          "doc": "Text and Typography",
          "title": "Mermaid SVG",
          "content": "\n\n<pre><code class=\"language-mermaid\"> gantt\n  title  Adding GANTT diagram functionality to mermaid\n  apple :a, 2017-07-20, 1w\n  banana :crit, b, 2017-07-23, 1d\n  cherry :active, c, after b a, 1d\n</code></pre>\n\n",
          "url": "/blog/text-and-typography/#mermaid-svg",
          
          "relUrl": "/blog/text-and-typography/#mermaid-svg"
        },
        "51": {
          "doc": "Text and Typography",
          "title": "Images",
          "content": "\n\n<h3 id=\"default-with-caption\">Default (with caption)</h3>\n\n<p><img src=\"https://chirpy-img.netlify.app/posts/20190808/mockup.png\" alt=\"Desktop View\" width=\"972\" height=\"589\" />\n<em>Full screen width and center alignment</em></p>\n\n<h3 id=\"left-aligned\">Left aligned</h3>\n\n<p><img src=\"https://chirpy-img.netlify.app/posts/20190808/mockup.png\" alt=\"Desktop View\" width=\"972\" height=\"589\" class=\"w-75 normal\" /></p>\n\n<h3 id=\"float-to-left\">Float to left</h3>\n\n<p><img src=\"https://chirpy-img.netlify.app/posts/20190808/mockup.png\" alt=\"Desktop View\" width=\"972\" height=\"589\" class=\"w-50 left\" />\nPraesent maximus aliquam sapien. Sed vel neque in dolor pulvinar auctor. Maecenas pharetra, sem sit amet interdum posuere, tellus lacus eleifend magna, ac lobortis felis ipsum id sapien. Proin ornare rutrum metus, ac convallis diam volutpat sit amet. Phasellus volutpat, elit sit amet tincidunt mollis, felis mi scelerisque mauris, ut facilisis leo magna accumsan sapien. In rutrum vehicula nisl eget tempor. Nullam maximus ullamcorper libero non maximus. Integer ultricies velit id convallis varius. Praesent eu nisl eu urna finibus ultrices id nec ex. Mauris ac mattis quam. Fusce aliquam est nec sapien bibendum, vitae malesuada ligula condimentum.</p>\n\n<h3 id=\"float-to-right\">Float to right</h3>\n\n<p><img src=\"https://chirpy-img.netlify.app/posts/20190808/mockup.png\" alt=\"Desktop View\" width=\"972\" height=\"589\" class=\"w-50 right\" />\nPraesent maximus aliquam sapien. Sed vel neque in dolor pulvinar auctor. Maecenas pharetra, sem sit amet interdum posuere, tellus lacus eleifend magna, ac lobortis felis ipsum id sapien. Proin ornare rutrum metus, ac convallis diam volutpat sit amet. Phasellus volutpat, elit sit amet tincidunt mollis, felis mi scelerisque mauris, ut facilisis leo magna accumsan sapien. In rutrum vehicula nisl eget tempor. Nullam maximus ullamcorper libero non maximus. Integer ultricies velit id convallis varius. Praesent eu nisl eu urna finibus ultrices id nec ex. Mauris ac mattis quam. Fusce aliquam est nec sapien bibendum, vitae malesuada ligula condimentum.</p>\n\n<h3 id=\"darklight-mode--shadow\">Dark/Light mode &amp; Shadow</h3>\n\n<p>The image below will toggle dark/light mode based on theme preference, notice it has shadows.</p>\n\n<p><img src=\"https://chirpy-img.netlify.app/posts/20190808/devtools-light.png\" alt=\"light mode only\" class=\"light w-75 shadow rounded-10\" w=\"1212\" h=\"668\" />\n<img src=\"https://chirpy-img.netlify.app/posts/20190808/devtools-dark.png\" alt=\"dark mode only\" class=\"dark w-75 shadow rounded-10\" w=\"1212\" h=\"668\" /></p>\n\n",
          "url": "/blog/text-and-typography/#images",
          
          "relUrl": "/blog/text-and-typography/#images"
        },
        "52": {
          "doc": "Text and Typography",
          "title": "Video",
          "content": "\n\n<iframe class=\"embed-video youtube\" loading=\"lazy\" src=\"https://www.youtube.com/embed/Balreaj8Yqs\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\"></iframe>\n\n",
          "url": "/blog/text-and-typography/#video",
          
          "relUrl": "/blog/text-and-typography/#video"
        },
        "53": {
          "doc": "Text and Typography",
          "title": "Reverse Footnote",
          "content": "\n\n<div class=\"footnotes\" role=\"doc-endnotes\">\n  <ol>\n    <li id=\"fn:footnote\" role=\"doc-endnote\">\n      <p>The footnote source <a href=\"#fnref:footnote\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;</a></p>\n    </li>\n    <li id=\"fn:fn-nth-2\" role=\"doc-endnote\">\n      <p>The 2nd footnote source <a href=\"#fnref:fn-nth-2\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;</a></p>\n    </li>\n  </ol>\n</div>\n",
          "url": "/blog/text-and-typography/#reverse-footnote",
          
          "relUrl": "/blog/text-and-typography/#reverse-footnote"
        },
        "54": {
          "doc": "Text and Typography",
          "title": "Text and Typography",
          "content": "<p>This post is to show Markdown syntax rendering on <a href=\"https://github.com/cotes2020/jekyll-theme-chirpy\"><strong>Chirpy</strong></a>, you can also use it as an example of writing. Now, let’s start looking at text and typography.</p>\n\n",
          "url": "/blog/text-and-typography/",
          
          "relUrl": "/blog/text-and-typography/"
        }
      ,
        "55": {
          "doc": "Blog",
          "title": "Blog",
          "content": null,
          "url": "/blog/",
          
          "relUrl": "/blog/"
        }
      ,
        "56": {
          "doc": "typography",
          "title": "typography",
          "content": null,
          "url": "/blog/tags/typography/",
          
          "relUrl": "/blog/tags/typography/"
        }
      ,
        "57": {
          "doc": "writing",
          "title": "writing",
          "content": null,
          "url": "/blog/tags/writing/",
          
          "relUrl": "/blog/tags/writing/"
        }
      ,
        "58": {
          "doc": "getting started",
          "title": "getting started",
          "content": null,
          "url": "/blog/tags/getting-started/",
          
          "relUrl": "/blog/tags/getting-started/"
        }
      ,
        "59": {
          "doc": "theme",
          "title": "theme",
          "content": null,
          "url": "/blog/tags/theme/",
          
          "relUrl": "/blog/tags/theme/"
        }
      ,
        "60": {
          "doc": "homepage",
          "title": "homepage",
          "content": null,
          "url": "/blog/tags/homepage/",
          
          "relUrl": "/blog/tags/homepage/"
        }
      ,
        "61": {
          "doc": "Blogging",
          "title": "Blogging",
          "content": null,
          "url": "/blog/categories/blogging/",
          
          "relUrl": "/blog/categories/blogging/"
        }
      ,
        "62": {
          "doc": "Demo",
          "title": "Demo",
          "content": null,
          "url": "/blog/categories/demo/",
          
          "relUrl": "/blog/categories/demo/"
        }
      ,
        "63": {
          "doc": "Tutorial",
          "title": "Tutorial",
          "content": null,
          "url": "/blog/categories/tutorial/",
          
          "relUrl": "/blog/categories/tutorial/"
        }
}
